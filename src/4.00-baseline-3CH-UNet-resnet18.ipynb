{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. baseline-3CH \n",
    "* 本bseline使用了smp中的U-Net，backbone为resnet101，仅使用RGB三通道\n",
    "* 初次使用日期2019.11.8\n",
    "* 未使用数据增强代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用2块显卡\n",
      "使用设备:cuda\n"
     ]
    }
   ],
   "source": [
    "# 所有图片使用RGB读入，没有做归一化\n",
    "import os \n",
    "import cv2\n",
    "import time \n",
    "import json \n",
    "import random \n",
    "import warnings\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score, cohen_kappa_score, jaccard_score\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms as T\n",
    "#from torchvision.models.segmentation import deeplabv3_resnet101\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from segmentation.utils import *\n",
    "\n",
    "# from segmentation.unet_plus import SE_Res50UNet, SE_Res101UNet\n",
    "import segmentation_models_pytorch as smp\n",
    "from torchsummaryX import summary\n",
    "\n",
    "GPU_ID = \"0,1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU_ID\n",
    "multiGPU = len(GPU_ID.split(','))-1\n",
    "print(\"使用%d块显卡\"%(multiGPU+1))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用设备:%s\"%(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'vgg16'\n",
    "SaveName = '05-baseline-3CH-UNet-seresnext50'\n",
    "EPOCHES = 400\n",
    "BS = 40\n",
    "SIZE = [576,576, 3]\n",
    "multiGPU = 0\n",
    "\n",
    "if not os.path.exists('../weights/'+SaveName):\n",
    "    os.makedirs('../weights/'+SaveName)\n",
    "        \n",
    "log = Logger()\n",
    "log.open(\"../logs/{}.txt\".format(SaveName),mode=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================================================\n",
      "                                                    Kernel Shape  \\\n",
      "Layer                                                              \n",
      "0_encoder.features.Conv2d_0                        [3, 64, 3, 3]   \n",
      "1_encoder.features.ReLU_1                                      -   \n",
      "2_encoder.features.Conv2d_2                       [64, 64, 3, 3]   \n",
      "3_encoder.features.ReLU_3                                      -   \n",
      "4_encoder.features.MaxPool2d_4                                 -   \n",
      "5_encoder.features.Conv2d_5                      [64, 128, 3, 3]   \n",
      "6_encoder.features.ReLU_6                                      -   \n",
      "7_encoder.features.Conv2d_7                     [128, 128, 3, 3]   \n",
      "8_encoder.features.ReLU_8                                      -   \n",
      "9_encoder.features.MaxPool2d_9                                 -   \n",
      "10_encoder.features.Conv2d_10                   [128, 256, 3, 3]   \n",
      "11_encoder.features.ReLU_11                                    -   \n",
      "12_encoder.features.Conv2d_12                   [256, 256, 3, 3]   \n",
      "13_encoder.features.ReLU_13                                    -   \n",
      "14_encoder.features.Conv2d_14                   [256, 256, 3, 3]   \n",
      "15_encoder.features.ReLU_15                                    -   \n",
      "16_encoder.features.MaxPool2d_16                               -   \n",
      "17_encoder.features.Conv2d_17                   [256, 512, 3, 3]   \n",
      "18_encoder.features.ReLU_18                                    -   \n",
      "19_encoder.features.Conv2d_19                   [512, 512, 3, 3]   \n",
      "20_encoder.features.ReLU_20                                    -   \n",
      "21_encoder.features.Conv2d_21                   [512, 512, 3, 3]   \n",
      "22_encoder.features.ReLU_22                                    -   \n",
      "23_encoder.features.MaxPool2d_23                               -   \n",
      "24_encoder.features.Conv2d_24                   [512, 512, 3, 3]   \n",
      "25_encoder.features.ReLU_25                                    -   \n",
      "26_encoder.features.Conv2d_26                   [512, 512, 3, 3]   \n",
      "27_encoder.features.ReLU_27                                    -   \n",
      "28_encoder.features.Conv2d_28                   [512, 512, 3, 3]   \n",
      "29_encoder.features.ReLU_29                                    -   \n",
      "30_encoder.features.MaxPool2d_30                               -   \n",
      "31_decoder.layer1.block.0.block.Conv2d_0       [1024, 256, 3, 3]   \n",
      "32_decoder.layer1.block.0.block.BatchNorm2d_1              [256]   \n",
      "33_decoder.layer1.block.0.block.ReLU_2                         -   \n",
      "34_decoder.layer1.block.1.block.Conv2d_0        [256, 256, 3, 3]   \n",
      "35_decoder.layer1.block.1.block.BatchNorm2d_1              [256]   \n",
      "36_decoder.layer1.block.1.block.ReLU_2                         -   \n",
      "37_decoder.layer2.block.0.block.Conv2d_0        [768, 128, 3, 3]   \n",
      "38_decoder.layer2.block.0.block.BatchNorm2d_1              [128]   \n",
      "39_decoder.layer2.block.0.block.ReLU_2                         -   \n",
      "40_decoder.layer2.block.1.block.Conv2d_0        [128, 128, 3, 3]   \n",
      "41_decoder.layer2.block.1.block.BatchNorm2d_1              [128]   \n",
      "42_decoder.layer2.block.1.block.ReLU_2                         -   \n",
      "43_decoder.layer3.block.0.block.Conv2d_0         [384, 64, 3, 3]   \n",
      "44_decoder.layer3.block.0.block.BatchNorm2d_1               [64]   \n",
      "45_decoder.layer3.block.0.block.ReLU_2                         -   \n",
      "46_decoder.layer3.block.1.block.Conv2d_0          [64, 64, 3, 3]   \n",
      "47_decoder.layer3.block.1.block.BatchNorm2d_1               [64]   \n",
      "48_decoder.layer3.block.1.block.ReLU_2                         -   \n",
      "49_decoder.layer4.block.0.block.Conv2d_0         [192, 32, 3, 3]   \n",
      "50_decoder.layer4.block.0.block.BatchNorm2d_1               [32]   \n",
      "51_decoder.layer4.block.0.block.ReLU_2                         -   \n",
      "52_decoder.layer4.block.1.block.Conv2d_0          [32, 32, 3, 3]   \n",
      "53_decoder.layer4.block.1.block.BatchNorm2d_1               [32]   \n",
      "54_decoder.layer4.block.1.block.ReLU_2                         -   \n",
      "55_decoder.layer5.block.0.block.Conv2d_0          [32, 16, 3, 3]   \n",
      "56_decoder.layer5.block.0.block.BatchNorm2d_1               [16]   \n",
      "57_decoder.layer5.block.0.block.ReLU_2                         -   \n",
      "58_decoder.layer5.block.1.block.Conv2d_0          [16, 16, 3, 3]   \n",
      "59_decoder.layer5.block.1.block.BatchNorm2d_1               [16]   \n",
      "60_decoder.layer5.block.1.block.ReLU_2                         -   \n",
      "61_decoder.Conv2d_final_conv                      [16, 16, 1, 1]   \n",
      "\n",
      "                                                     Output Shape     Params  \\\n",
      "Layer                                                                          \n",
      "0_encoder.features.Conv2d_0                     [3, 64, 576, 576]     1.792k   \n",
      "1_encoder.features.ReLU_1                       [3, 64, 576, 576]          -   \n",
      "2_encoder.features.Conv2d_2                     [3, 64, 576, 576]    36.928k   \n",
      "3_encoder.features.ReLU_3                       [3, 64, 576, 576]          -   \n",
      "4_encoder.features.MaxPool2d_4                  [3, 64, 288, 288]          -   \n",
      "5_encoder.features.Conv2d_5                    [3, 128, 288, 288]    73.856k   \n",
      "6_encoder.features.ReLU_6                      [3, 128, 288, 288]          -   \n",
      "7_encoder.features.Conv2d_7                    [3, 128, 288, 288]   147.584k   \n",
      "8_encoder.features.ReLU_8                      [3, 128, 288, 288]          -   \n",
      "9_encoder.features.MaxPool2d_9                 [3, 128, 144, 144]          -   \n",
      "10_encoder.features.Conv2d_10                  [3, 256, 144, 144]   295.168k   \n",
      "11_encoder.features.ReLU_11                    [3, 256, 144, 144]          -   \n",
      "12_encoder.features.Conv2d_12                  [3, 256, 144, 144]    590.08k   \n",
      "13_encoder.features.ReLU_13                    [3, 256, 144, 144]          -   \n",
      "14_encoder.features.Conv2d_14                  [3, 256, 144, 144]    590.08k   \n",
      "15_encoder.features.ReLU_15                    [3, 256, 144, 144]          -   \n",
      "16_encoder.features.MaxPool2d_16                 [3, 256, 72, 72]          -   \n",
      "17_encoder.features.Conv2d_17                    [3, 512, 72, 72]   1.18016M   \n",
      "18_encoder.features.ReLU_18                      [3, 512, 72, 72]          -   \n",
      "19_encoder.features.Conv2d_19                    [3, 512, 72, 72]  2.359808M   \n",
      "20_encoder.features.ReLU_20                      [3, 512, 72, 72]          -   \n",
      "21_encoder.features.Conv2d_21                    [3, 512, 72, 72]  2.359808M   \n",
      "22_encoder.features.ReLU_22                      [3, 512, 72, 72]          -   \n",
      "23_encoder.features.MaxPool2d_23                 [3, 512, 36, 36]          -   \n",
      "24_encoder.features.Conv2d_24                    [3, 512, 36, 36]  2.359808M   \n",
      "25_encoder.features.ReLU_25                      [3, 512, 36, 36]          -   \n",
      "26_encoder.features.Conv2d_26                    [3, 512, 36, 36]  2.359808M   \n",
      "27_encoder.features.ReLU_27                      [3, 512, 36, 36]          -   \n",
      "28_encoder.features.Conv2d_28                    [3, 512, 36, 36]  2.359808M   \n",
      "29_encoder.features.ReLU_29                      [3, 512, 36, 36]          -   \n",
      "30_encoder.features.MaxPool2d_30                 [3, 512, 18, 18]          -   \n",
      "31_decoder.layer1.block.0.block.Conv2d_0         [3, 256, 36, 36]  2.359296M   \n",
      "32_decoder.layer1.block.0.block.BatchNorm2d_1    [3, 256, 36, 36]      512.0   \n",
      "33_decoder.layer1.block.0.block.ReLU_2           [3, 256, 36, 36]          -   \n",
      "34_decoder.layer1.block.1.block.Conv2d_0         [3, 256, 36, 36]   589.824k   \n",
      "35_decoder.layer1.block.1.block.BatchNorm2d_1    [3, 256, 36, 36]      512.0   \n",
      "36_decoder.layer1.block.1.block.ReLU_2           [3, 256, 36, 36]          -   \n",
      "37_decoder.layer2.block.0.block.Conv2d_0         [3, 128, 72, 72]   884.736k   \n",
      "38_decoder.layer2.block.0.block.BatchNorm2d_1    [3, 128, 72, 72]      256.0   \n",
      "39_decoder.layer2.block.0.block.ReLU_2           [3, 128, 72, 72]          -   \n",
      "40_decoder.layer2.block.1.block.Conv2d_0         [3, 128, 72, 72]   147.456k   \n",
      "41_decoder.layer2.block.1.block.BatchNorm2d_1    [3, 128, 72, 72]      256.0   \n",
      "42_decoder.layer2.block.1.block.ReLU_2           [3, 128, 72, 72]          -   \n",
      "43_decoder.layer3.block.0.block.Conv2d_0        [3, 64, 144, 144]   221.184k   \n",
      "44_decoder.layer3.block.0.block.BatchNorm2d_1   [3, 64, 144, 144]      128.0   \n",
      "45_decoder.layer3.block.0.block.ReLU_2          [3, 64, 144, 144]          -   \n",
      "46_decoder.layer3.block.1.block.Conv2d_0        [3, 64, 144, 144]    36.864k   \n",
      "47_decoder.layer3.block.1.block.BatchNorm2d_1   [3, 64, 144, 144]      128.0   \n",
      "48_decoder.layer3.block.1.block.ReLU_2          [3, 64, 144, 144]          -   \n",
      "49_decoder.layer4.block.0.block.Conv2d_0        [3, 32, 288, 288]    55.296k   \n",
      "50_decoder.layer4.block.0.block.BatchNorm2d_1   [3, 32, 288, 288]       64.0   \n",
      "51_decoder.layer4.block.0.block.ReLU_2          [3, 32, 288, 288]          -   \n",
      "52_decoder.layer4.block.1.block.Conv2d_0        [3, 32, 288, 288]     9.216k   \n",
      "53_decoder.layer4.block.1.block.BatchNorm2d_1   [3, 32, 288, 288]       64.0   \n",
      "54_decoder.layer4.block.1.block.ReLU_2          [3, 32, 288, 288]          -   \n",
      "55_decoder.layer5.block.0.block.Conv2d_0        [3, 16, 576, 576]     4.608k   \n",
      "56_decoder.layer5.block.0.block.BatchNorm2d_1   [3, 16, 576, 576]       32.0   \n",
      "57_decoder.layer5.block.0.block.ReLU_2          [3, 16, 576, 576]          -   \n",
      "58_decoder.layer5.block.1.block.Conv2d_0        [3, 16, 576, 576]     2.304k   \n",
      "59_decoder.layer5.block.1.block.BatchNorm2d_1   [3, 16, 576, 576]       32.0   \n",
      "60_decoder.layer5.block.1.block.ReLU_2          [3, 16, 576, 576]          -   \n",
      "61_decoder.Conv2d_final_conv                    [3, 16, 576, 576]      272.0   \n",
      "\n",
      "                                                   Mult-Adds  \n",
      "Layer                                                         \n",
      "0_encoder.features.Conv2d_0                      573.308928M  \n",
      "1_encoder.features.ReLU_1                                  -  \n",
      "2_encoder.features.Conv2d_2                    12.230590464G  \n",
      "3_encoder.features.ReLU_3                                  -  \n",
      "4_encoder.features.MaxPool2d_4                             -  \n",
      "5_encoder.features.Conv2d_5                     6.115295232G  \n",
      "6_encoder.features.ReLU_6                                  -  \n",
      "7_encoder.features.Conv2d_7                    12.230590464G  \n",
      "8_encoder.features.ReLU_8                                  -  \n",
      "9_encoder.features.MaxPool2d_9                             -  \n",
      "10_encoder.features.Conv2d_10                   6.115295232G  \n",
      "11_encoder.features.ReLU_11                                -  \n",
      "12_encoder.features.Conv2d_12                  12.230590464G  \n",
      "13_encoder.features.ReLU_13                                -  \n",
      "14_encoder.features.Conv2d_14                  12.230590464G  \n",
      "15_encoder.features.ReLU_15                                -  \n",
      "16_encoder.features.MaxPool2d_16                           -  \n",
      "17_encoder.features.Conv2d_17                   6.115295232G  \n",
      "18_encoder.features.ReLU_18                                -  \n",
      "19_encoder.features.Conv2d_19                  12.230590464G  \n",
      "20_encoder.features.ReLU_20                                -  \n",
      "21_encoder.features.Conv2d_21                  12.230590464G  \n",
      "22_encoder.features.ReLU_22                                -  \n",
      "23_encoder.features.MaxPool2d_23                           -  \n",
      "24_encoder.features.Conv2d_24                   3.057647616G  \n",
      "25_encoder.features.ReLU_25                                -  \n",
      "26_encoder.features.Conv2d_26                   3.057647616G  \n",
      "27_encoder.features.ReLU_27                                -  \n",
      "28_encoder.features.Conv2d_28                   3.057647616G  \n",
      "29_encoder.features.ReLU_29                                -  \n",
      "30_encoder.features.MaxPool2d_30                           -  \n",
      "31_decoder.layer1.block.0.block.Conv2d_0        3.057647616G  \n",
      "32_decoder.layer1.block.0.block.BatchNorm2d_1          256.0  \n",
      "33_decoder.layer1.block.0.block.ReLU_2                     -  \n",
      "34_decoder.layer1.block.1.block.Conv2d_0         764.411904M  \n",
      "35_decoder.layer1.block.1.block.BatchNorm2d_1          256.0  \n",
      "36_decoder.layer1.block.1.block.ReLU_2                     -  \n",
      "37_decoder.layer2.block.0.block.Conv2d_0        4.586471424G  \n",
      "38_decoder.layer2.block.0.block.BatchNorm2d_1          128.0  \n",
      "39_decoder.layer2.block.0.block.ReLU_2                     -  \n",
      "40_decoder.layer2.block.1.block.Conv2d_0         764.411904M  \n",
      "41_decoder.layer2.block.1.block.BatchNorm2d_1          128.0  \n",
      "42_decoder.layer2.block.1.block.ReLU_2                     -  \n",
      "43_decoder.layer3.block.0.block.Conv2d_0        4.586471424G  \n",
      "44_decoder.layer3.block.0.block.BatchNorm2d_1           64.0  \n",
      "45_decoder.layer3.block.0.block.ReLU_2                     -  \n",
      "46_decoder.layer3.block.1.block.Conv2d_0         764.411904M  \n",
      "47_decoder.layer3.block.1.block.BatchNorm2d_1           64.0  \n",
      "48_decoder.layer3.block.1.block.ReLU_2                     -  \n",
      "49_decoder.layer4.block.0.block.Conv2d_0        4.586471424G  \n",
      "50_decoder.layer4.block.0.block.BatchNorm2d_1           32.0  \n",
      "51_decoder.layer4.block.0.block.ReLU_2                     -  \n",
      "52_decoder.layer4.block.1.block.Conv2d_0         764.411904M  \n",
      "53_decoder.layer4.block.1.block.BatchNorm2d_1           32.0  \n",
      "54_decoder.layer4.block.1.block.ReLU_2                     -  \n",
      "55_decoder.layer5.block.0.block.Conv2d_0        1.528823808G  \n",
      "56_decoder.layer5.block.0.block.BatchNorm2d_1           16.0  \n",
      "57_decoder.layer5.block.0.block.ReLU_2                     -  \n",
      "58_decoder.layer5.block.1.block.Conv2d_0         764.411904M  \n",
      "59_decoder.layer5.block.1.block.BatchNorm2d_1           16.0  \n",
      "60_decoder.layer5.block.1.block.ReLU_2                     -  \n",
      "61_decoder.Conv2d_final_conv                      84.934656M  \n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "                             Totals\n",
      "Total params             19.027728M\n",
      "Trainable params         19.027728M\n",
      "Non-trainable params            0.0\n",
      "Mult-Adds             123.72856112G\n",
      "=============================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_encoder.features.Conv2d_0</th>\n",
       "      <td>[3, 64, 3, 3]</td>\n",
       "      <td>[3, 64, 576, 576]</td>\n",
       "      <td>1792.0</td>\n",
       "      <td>5.733089e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_encoder.features.ReLU_1</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 64, 576, 576]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_encoder.features.Conv2d_2</th>\n",
       "      <td>[64, 64, 3, 3]</td>\n",
       "      <td>[3, 64, 576, 576]</td>\n",
       "      <td>36928.0</td>\n",
       "      <td>1.223059e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_encoder.features.ReLU_3</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 64, 576, 576]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_encoder.features.MaxPool2d_4</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 64, 288, 288]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_encoder.features.Conv2d_5</th>\n",
       "      <td>[64, 128, 3, 3]</td>\n",
       "      <td>[3, 128, 288, 288]</td>\n",
       "      <td>73856.0</td>\n",
       "      <td>6.115295e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_encoder.features.ReLU_6</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 128, 288, 288]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_encoder.features.Conv2d_7</th>\n",
       "      <td>[128, 128, 3, 3]</td>\n",
       "      <td>[3, 128, 288, 288]</td>\n",
       "      <td>147584.0</td>\n",
       "      <td>1.223059e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8_encoder.features.ReLU_8</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 128, 288, 288]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_encoder.features.MaxPool2d_9</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 128, 144, 144]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10_encoder.features.Conv2d_10</th>\n",
       "      <td>[128, 256, 3, 3]</td>\n",
       "      <td>[3, 256, 144, 144]</td>\n",
       "      <td>295168.0</td>\n",
       "      <td>6.115295e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11_encoder.features.ReLU_11</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 256, 144, 144]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_encoder.features.Conv2d_12</th>\n",
       "      <td>[256, 256, 3, 3]</td>\n",
       "      <td>[3, 256, 144, 144]</td>\n",
       "      <td>590080.0</td>\n",
       "      <td>1.223059e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13_encoder.features.ReLU_13</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 256, 144, 144]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14_encoder.features.Conv2d_14</th>\n",
       "      <td>[256, 256, 3, 3]</td>\n",
       "      <td>[3, 256, 144, 144]</td>\n",
       "      <td>590080.0</td>\n",
       "      <td>1.223059e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15_encoder.features.ReLU_15</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 256, 144, 144]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16_encoder.features.MaxPool2d_16</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 256, 72, 72]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17_encoder.features.Conv2d_17</th>\n",
       "      <td>[256, 512, 3, 3]</td>\n",
       "      <td>[3, 512, 72, 72]</td>\n",
       "      <td>1180160.0</td>\n",
       "      <td>6.115295e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18_encoder.features.ReLU_18</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 512, 72, 72]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19_encoder.features.Conv2d_19</th>\n",
       "      <td>[512, 512, 3, 3]</td>\n",
       "      <td>[3, 512, 72, 72]</td>\n",
       "      <td>2359808.0</td>\n",
       "      <td>1.223059e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_encoder.features.ReLU_20</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 512, 72, 72]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21_encoder.features.Conv2d_21</th>\n",
       "      <td>[512, 512, 3, 3]</td>\n",
       "      <td>[3, 512, 72, 72]</td>\n",
       "      <td>2359808.0</td>\n",
       "      <td>1.223059e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22_encoder.features.ReLU_22</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 512, 72, 72]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23_encoder.features.MaxPool2d_23</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 512, 36, 36]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24_encoder.features.Conv2d_24</th>\n",
       "      <td>[512, 512, 3, 3]</td>\n",
       "      <td>[3, 512, 36, 36]</td>\n",
       "      <td>2359808.0</td>\n",
       "      <td>3.057648e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25_encoder.features.ReLU_25</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 512, 36, 36]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26_encoder.features.Conv2d_26</th>\n",
       "      <td>[512, 512, 3, 3]</td>\n",
       "      <td>[3, 512, 36, 36]</td>\n",
       "      <td>2359808.0</td>\n",
       "      <td>3.057648e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27_encoder.features.ReLU_27</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 512, 36, 36]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28_encoder.features.Conv2d_28</th>\n",
       "      <td>[512, 512, 3, 3]</td>\n",
       "      <td>[3, 512, 36, 36]</td>\n",
       "      <td>2359808.0</td>\n",
       "      <td>3.057648e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29_encoder.features.ReLU_29</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 512, 36, 36]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32_decoder.layer1.block.0.block.BatchNorm2d_1</th>\n",
       "      <td>[256]</td>\n",
       "      <td>[3, 256, 36, 36]</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2.560000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33_decoder.layer1.block.0.block.ReLU_2</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 256, 36, 36]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34_decoder.layer1.block.1.block.Conv2d_0</th>\n",
       "      <td>[256, 256, 3, 3]</td>\n",
       "      <td>[3, 256, 36, 36]</td>\n",
       "      <td>589824.0</td>\n",
       "      <td>7.644119e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35_decoder.layer1.block.1.block.BatchNorm2d_1</th>\n",
       "      <td>[256]</td>\n",
       "      <td>[3, 256, 36, 36]</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2.560000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36_decoder.layer1.block.1.block.ReLU_2</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 256, 36, 36]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37_decoder.layer2.block.0.block.Conv2d_0</th>\n",
       "      <td>[768, 128, 3, 3]</td>\n",
       "      <td>[3, 128, 72, 72]</td>\n",
       "      <td>884736.0</td>\n",
       "      <td>4.586471e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38_decoder.layer2.block.0.block.BatchNorm2d_1</th>\n",
       "      <td>[128]</td>\n",
       "      <td>[3, 128, 72, 72]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.280000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39_decoder.layer2.block.0.block.ReLU_2</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 128, 72, 72]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40_decoder.layer2.block.1.block.Conv2d_0</th>\n",
       "      <td>[128, 128, 3, 3]</td>\n",
       "      <td>[3, 128, 72, 72]</td>\n",
       "      <td>147456.0</td>\n",
       "      <td>7.644119e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41_decoder.layer2.block.1.block.BatchNorm2d_1</th>\n",
       "      <td>[128]</td>\n",
       "      <td>[3, 128, 72, 72]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.280000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42_decoder.layer2.block.1.block.ReLU_2</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 128, 72, 72]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43_decoder.layer3.block.0.block.Conv2d_0</th>\n",
       "      <td>[384, 64, 3, 3]</td>\n",
       "      <td>[3, 64, 144, 144]</td>\n",
       "      <td>221184.0</td>\n",
       "      <td>4.586471e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44_decoder.layer3.block.0.block.BatchNorm2d_1</th>\n",
       "      <td>[64]</td>\n",
       "      <td>[3, 64, 144, 144]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>6.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45_decoder.layer3.block.0.block.ReLU_2</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 64, 144, 144]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46_decoder.layer3.block.1.block.Conv2d_0</th>\n",
       "      <td>[64, 64, 3, 3]</td>\n",
       "      <td>[3, 64, 144, 144]</td>\n",
       "      <td>36864.0</td>\n",
       "      <td>7.644119e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47_decoder.layer3.block.1.block.BatchNorm2d_1</th>\n",
       "      <td>[64]</td>\n",
       "      <td>[3, 64, 144, 144]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>6.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48_decoder.layer3.block.1.block.ReLU_2</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 64, 144, 144]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49_decoder.layer4.block.0.block.Conv2d_0</th>\n",
       "      <td>[192, 32, 3, 3]</td>\n",
       "      <td>[3, 32, 288, 288]</td>\n",
       "      <td>55296.0</td>\n",
       "      <td>4.586471e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50_decoder.layer4.block.0.block.BatchNorm2d_1</th>\n",
       "      <td>[32]</td>\n",
       "      <td>[3, 32, 288, 288]</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51_decoder.layer4.block.0.block.ReLU_2</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 32, 288, 288]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52_decoder.layer4.block.1.block.Conv2d_0</th>\n",
       "      <td>[32, 32, 3, 3]</td>\n",
       "      <td>[3, 32, 288, 288]</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>7.644119e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53_decoder.layer4.block.1.block.BatchNorm2d_1</th>\n",
       "      <td>[32]</td>\n",
       "      <td>[3, 32, 288, 288]</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54_decoder.layer4.block.1.block.ReLU_2</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 32, 288, 288]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_decoder.layer5.block.0.block.Conv2d_0</th>\n",
       "      <td>[32, 16, 3, 3]</td>\n",
       "      <td>[3, 16, 576, 576]</td>\n",
       "      <td>4608.0</td>\n",
       "      <td>1.528824e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56_decoder.layer5.block.0.block.BatchNorm2d_1</th>\n",
       "      <td>[16]</td>\n",
       "      <td>[3, 16, 576, 576]</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57_decoder.layer5.block.0.block.ReLU_2</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 16, 576, 576]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58_decoder.layer5.block.1.block.Conv2d_0</th>\n",
       "      <td>[16, 16, 3, 3]</td>\n",
       "      <td>[3, 16, 576, 576]</td>\n",
       "      <td>2304.0</td>\n",
       "      <td>7.644119e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59_decoder.layer5.block.1.block.BatchNorm2d_1</th>\n",
       "      <td>[16]</td>\n",
       "      <td>[3, 16, 576, 576]</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60_decoder.layer5.block.1.block.ReLU_2</th>\n",
       "      <td>-</td>\n",
       "      <td>[3, 16, 576, 576]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61_decoder.Conv2d_final_conv</th>\n",
       "      <td>[16, 16, 1, 1]</td>\n",
       "      <td>[3, 16, 576, 576]</td>\n",
       "      <td>272.0</td>\n",
       "      <td>8.493466e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Kernel Shape  \\\n",
       "Layer                                                             \n",
       "0_encoder.features.Conv2d_0                       [3, 64, 3, 3]   \n",
       "1_encoder.features.ReLU_1                                     -   \n",
       "2_encoder.features.Conv2d_2                      [64, 64, 3, 3]   \n",
       "3_encoder.features.ReLU_3                                     -   \n",
       "4_encoder.features.MaxPool2d_4                                -   \n",
       "5_encoder.features.Conv2d_5                     [64, 128, 3, 3]   \n",
       "6_encoder.features.ReLU_6                                     -   \n",
       "7_encoder.features.Conv2d_7                    [128, 128, 3, 3]   \n",
       "8_encoder.features.ReLU_8                                     -   \n",
       "9_encoder.features.MaxPool2d_9                                -   \n",
       "10_encoder.features.Conv2d_10                  [128, 256, 3, 3]   \n",
       "11_encoder.features.ReLU_11                                   -   \n",
       "12_encoder.features.Conv2d_12                  [256, 256, 3, 3]   \n",
       "13_encoder.features.ReLU_13                                   -   \n",
       "14_encoder.features.Conv2d_14                  [256, 256, 3, 3]   \n",
       "15_encoder.features.ReLU_15                                   -   \n",
       "16_encoder.features.MaxPool2d_16                              -   \n",
       "17_encoder.features.Conv2d_17                  [256, 512, 3, 3]   \n",
       "18_encoder.features.ReLU_18                                   -   \n",
       "19_encoder.features.Conv2d_19                  [512, 512, 3, 3]   \n",
       "20_encoder.features.ReLU_20                                   -   \n",
       "21_encoder.features.Conv2d_21                  [512, 512, 3, 3]   \n",
       "22_encoder.features.ReLU_22                                   -   \n",
       "23_encoder.features.MaxPool2d_23                              -   \n",
       "24_encoder.features.Conv2d_24                  [512, 512, 3, 3]   \n",
       "25_encoder.features.ReLU_25                                   -   \n",
       "26_encoder.features.Conv2d_26                  [512, 512, 3, 3]   \n",
       "27_encoder.features.ReLU_27                                   -   \n",
       "28_encoder.features.Conv2d_28                  [512, 512, 3, 3]   \n",
       "29_encoder.features.ReLU_29                                   -   \n",
       "...                                                         ...   \n",
       "32_decoder.layer1.block.0.block.BatchNorm2d_1             [256]   \n",
       "33_decoder.layer1.block.0.block.ReLU_2                        -   \n",
       "34_decoder.layer1.block.1.block.Conv2d_0       [256, 256, 3, 3]   \n",
       "35_decoder.layer1.block.1.block.BatchNorm2d_1             [256]   \n",
       "36_decoder.layer1.block.1.block.ReLU_2                        -   \n",
       "37_decoder.layer2.block.0.block.Conv2d_0       [768, 128, 3, 3]   \n",
       "38_decoder.layer2.block.0.block.BatchNorm2d_1             [128]   \n",
       "39_decoder.layer2.block.0.block.ReLU_2                        -   \n",
       "40_decoder.layer2.block.1.block.Conv2d_0       [128, 128, 3, 3]   \n",
       "41_decoder.layer2.block.1.block.BatchNorm2d_1             [128]   \n",
       "42_decoder.layer2.block.1.block.ReLU_2                        -   \n",
       "43_decoder.layer3.block.0.block.Conv2d_0        [384, 64, 3, 3]   \n",
       "44_decoder.layer3.block.0.block.BatchNorm2d_1              [64]   \n",
       "45_decoder.layer3.block.0.block.ReLU_2                        -   \n",
       "46_decoder.layer3.block.1.block.Conv2d_0         [64, 64, 3, 3]   \n",
       "47_decoder.layer3.block.1.block.BatchNorm2d_1              [64]   \n",
       "48_decoder.layer3.block.1.block.ReLU_2                        -   \n",
       "49_decoder.layer4.block.0.block.Conv2d_0        [192, 32, 3, 3]   \n",
       "50_decoder.layer4.block.0.block.BatchNorm2d_1              [32]   \n",
       "51_decoder.layer4.block.0.block.ReLU_2                        -   \n",
       "52_decoder.layer4.block.1.block.Conv2d_0         [32, 32, 3, 3]   \n",
       "53_decoder.layer4.block.1.block.BatchNorm2d_1              [32]   \n",
       "54_decoder.layer4.block.1.block.ReLU_2                        -   \n",
       "55_decoder.layer5.block.0.block.Conv2d_0         [32, 16, 3, 3]   \n",
       "56_decoder.layer5.block.0.block.BatchNorm2d_1              [16]   \n",
       "57_decoder.layer5.block.0.block.ReLU_2                        -   \n",
       "58_decoder.layer5.block.1.block.Conv2d_0         [16, 16, 3, 3]   \n",
       "59_decoder.layer5.block.1.block.BatchNorm2d_1              [16]   \n",
       "60_decoder.layer5.block.1.block.ReLU_2                        -   \n",
       "61_decoder.Conv2d_final_conv                     [16, 16, 1, 1]   \n",
       "\n",
       "                                                     Output Shape     Params  \\\n",
       "Layer                                                                          \n",
       "0_encoder.features.Conv2d_0                     [3, 64, 576, 576]     1792.0   \n",
       "1_encoder.features.ReLU_1                       [3, 64, 576, 576]        NaN   \n",
       "2_encoder.features.Conv2d_2                     [3, 64, 576, 576]    36928.0   \n",
       "3_encoder.features.ReLU_3                       [3, 64, 576, 576]        NaN   \n",
       "4_encoder.features.MaxPool2d_4                  [3, 64, 288, 288]        NaN   \n",
       "5_encoder.features.Conv2d_5                    [3, 128, 288, 288]    73856.0   \n",
       "6_encoder.features.ReLU_6                      [3, 128, 288, 288]        NaN   \n",
       "7_encoder.features.Conv2d_7                    [3, 128, 288, 288]   147584.0   \n",
       "8_encoder.features.ReLU_8                      [3, 128, 288, 288]        NaN   \n",
       "9_encoder.features.MaxPool2d_9                 [3, 128, 144, 144]        NaN   \n",
       "10_encoder.features.Conv2d_10                  [3, 256, 144, 144]   295168.0   \n",
       "11_encoder.features.ReLU_11                    [3, 256, 144, 144]        NaN   \n",
       "12_encoder.features.Conv2d_12                  [3, 256, 144, 144]   590080.0   \n",
       "13_encoder.features.ReLU_13                    [3, 256, 144, 144]        NaN   \n",
       "14_encoder.features.Conv2d_14                  [3, 256, 144, 144]   590080.0   \n",
       "15_encoder.features.ReLU_15                    [3, 256, 144, 144]        NaN   \n",
       "16_encoder.features.MaxPool2d_16                 [3, 256, 72, 72]        NaN   \n",
       "17_encoder.features.Conv2d_17                    [3, 512, 72, 72]  1180160.0   \n",
       "18_encoder.features.ReLU_18                      [3, 512, 72, 72]        NaN   \n",
       "19_encoder.features.Conv2d_19                    [3, 512, 72, 72]  2359808.0   \n",
       "20_encoder.features.ReLU_20                      [3, 512, 72, 72]        NaN   \n",
       "21_encoder.features.Conv2d_21                    [3, 512, 72, 72]  2359808.0   \n",
       "22_encoder.features.ReLU_22                      [3, 512, 72, 72]        NaN   \n",
       "23_encoder.features.MaxPool2d_23                 [3, 512, 36, 36]        NaN   \n",
       "24_encoder.features.Conv2d_24                    [3, 512, 36, 36]  2359808.0   \n",
       "25_encoder.features.ReLU_25                      [3, 512, 36, 36]        NaN   \n",
       "26_encoder.features.Conv2d_26                    [3, 512, 36, 36]  2359808.0   \n",
       "27_encoder.features.ReLU_27                      [3, 512, 36, 36]        NaN   \n",
       "28_encoder.features.Conv2d_28                    [3, 512, 36, 36]  2359808.0   \n",
       "29_encoder.features.ReLU_29                      [3, 512, 36, 36]        NaN   \n",
       "...                                                           ...        ...   \n",
       "32_decoder.layer1.block.0.block.BatchNorm2d_1    [3, 256, 36, 36]      512.0   \n",
       "33_decoder.layer1.block.0.block.ReLU_2           [3, 256, 36, 36]        NaN   \n",
       "34_decoder.layer1.block.1.block.Conv2d_0         [3, 256, 36, 36]   589824.0   \n",
       "35_decoder.layer1.block.1.block.BatchNorm2d_1    [3, 256, 36, 36]      512.0   \n",
       "36_decoder.layer1.block.1.block.ReLU_2           [3, 256, 36, 36]        NaN   \n",
       "37_decoder.layer2.block.0.block.Conv2d_0         [3, 128, 72, 72]   884736.0   \n",
       "38_decoder.layer2.block.0.block.BatchNorm2d_1    [3, 128, 72, 72]      256.0   \n",
       "39_decoder.layer2.block.0.block.ReLU_2           [3, 128, 72, 72]        NaN   \n",
       "40_decoder.layer2.block.1.block.Conv2d_0         [3, 128, 72, 72]   147456.0   \n",
       "41_decoder.layer2.block.1.block.BatchNorm2d_1    [3, 128, 72, 72]      256.0   \n",
       "42_decoder.layer2.block.1.block.ReLU_2           [3, 128, 72, 72]        NaN   \n",
       "43_decoder.layer3.block.0.block.Conv2d_0        [3, 64, 144, 144]   221184.0   \n",
       "44_decoder.layer3.block.0.block.BatchNorm2d_1   [3, 64, 144, 144]      128.0   \n",
       "45_decoder.layer3.block.0.block.ReLU_2          [3, 64, 144, 144]        NaN   \n",
       "46_decoder.layer3.block.1.block.Conv2d_0        [3, 64, 144, 144]    36864.0   \n",
       "47_decoder.layer3.block.1.block.BatchNorm2d_1   [3, 64, 144, 144]      128.0   \n",
       "48_decoder.layer3.block.1.block.ReLU_2          [3, 64, 144, 144]        NaN   \n",
       "49_decoder.layer4.block.0.block.Conv2d_0        [3, 32, 288, 288]    55296.0   \n",
       "50_decoder.layer4.block.0.block.BatchNorm2d_1   [3, 32, 288, 288]       64.0   \n",
       "51_decoder.layer4.block.0.block.ReLU_2          [3, 32, 288, 288]        NaN   \n",
       "52_decoder.layer4.block.1.block.Conv2d_0        [3, 32, 288, 288]     9216.0   \n",
       "53_decoder.layer4.block.1.block.BatchNorm2d_1   [3, 32, 288, 288]       64.0   \n",
       "54_decoder.layer4.block.1.block.ReLU_2          [3, 32, 288, 288]        NaN   \n",
       "55_decoder.layer5.block.0.block.Conv2d_0        [3, 16, 576, 576]     4608.0   \n",
       "56_decoder.layer5.block.0.block.BatchNorm2d_1   [3, 16, 576, 576]       32.0   \n",
       "57_decoder.layer5.block.0.block.ReLU_2          [3, 16, 576, 576]        NaN   \n",
       "58_decoder.layer5.block.1.block.Conv2d_0        [3, 16, 576, 576]     2304.0   \n",
       "59_decoder.layer5.block.1.block.BatchNorm2d_1   [3, 16, 576, 576]       32.0   \n",
       "60_decoder.layer5.block.1.block.ReLU_2          [3, 16, 576, 576]        NaN   \n",
       "61_decoder.Conv2d_final_conv                    [3, 16, 576, 576]      272.0   \n",
       "\n",
       "                                                  Mult-Adds  \n",
       "Layer                                                        \n",
       "0_encoder.features.Conv2d_0                    5.733089e+08  \n",
       "1_encoder.features.ReLU_1                               NaN  \n",
       "2_encoder.features.Conv2d_2                    1.223059e+10  \n",
       "3_encoder.features.ReLU_3                               NaN  \n",
       "4_encoder.features.MaxPool2d_4                          NaN  \n",
       "5_encoder.features.Conv2d_5                    6.115295e+09  \n",
       "6_encoder.features.ReLU_6                               NaN  \n",
       "7_encoder.features.Conv2d_7                    1.223059e+10  \n",
       "8_encoder.features.ReLU_8                               NaN  \n",
       "9_encoder.features.MaxPool2d_9                          NaN  \n",
       "10_encoder.features.Conv2d_10                  6.115295e+09  \n",
       "11_encoder.features.ReLU_11                             NaN  \n",
       "12_encoder.features.Conv2d_12                  1.223059e+10  \n",
       "13_encoder.features.ReLU_13                             NaN  \n",
       "14_encoder.features.Conv2d_14                  1.223059e+10  \n",
       "15_encoder.features.ReLU_15                             NaN  \n",
       "16_encoder.features.MaxPool2d_16                        NaN  \n",
       "17_encoder.features.Conv2d_17                  6.115295e+09  \n",
       "18_encoder.features.ReLU_18                             NaN  \n",
       "19_encoder.features.Conv2d_19                  1.223059e+10  \n",
       "20_encoder.features.ReLU_20                             NaN  \n",
       "21_encoder.features.Conv2d_21                  1.223059e+10  \n",
       "22_encoder.features.ReLU_22                             NaN  \n",
       "23_encoder.features.MaxPool2d_23                        NaN  \n",
       "24_encoder.features.Conv2d_24                  3.057648e+09  \n",
       "25_encoder.features.ReLU_25                             NaN  \n",
       "26_encoder.features.Conv2d_26                  3.057648e+09  \n",
       "27_encoder.features.ReLU_27                             NaN  \n",
       "28_encoder.features.Conv2d_28                  3.057648e+09  \n",
       "29_encoder.features.ReLU_29                             NaN  \n",
       "...                                                     ...  \n",
       "32_decoder.layer1.block.0.block.BatchNorm2d_1  2.560000e+02  \n",
       "33_decoder.layer1.block.0.block.ReLU_2                  NaN  \n",
       "34_decoder.layer1.block.1.block.Conv2d_0       7.644119e+08  \n",
       "35_decoder.layer1.block.1.block.BatchNorm2d_1  2.560000e+02  \n",
       "36_decoder.layer1.block.1.block.ReLU_2                  NaN  \n",
       "37_decoder.layer2.block.0.block.Conv2d_0       4.586471e+09  \n",
       "38_decoder.layer2.block.0.block.BatchNorm2d_1  1.280000e+02  \n",
       "39_decoder.layer2.block.0.block.ReLU_2                  NaN  \n",
       "40_decoder.layer2.block.1.block.Conv2d_0       7.644119e+08  \n",
       "41_decoder.layer2.block.1.block.BatchNorm2d_1  1.280000e+02  \n",
       "42_decoder.layer2.block.1.block.ReLU_2                  NaN  \n",
       "43_decoder.layer3.block.0.block.Conv2d_0       4.586471e+09  \n",
       "44_decoder.layer3.block.0.block.BatchNorm2d_1  6.400000e+01  \n",
       "45_decoder.layer3.block.0.block.ReLU_2                  NaN  \n",
       "46_decoder.layer3.block.1.block.Conv2d_0       7.644119e+08  \n",
       "47_decoder.layer3.block.1.block.BatchNorm2d_1  6.400000e+01  \n",
       "48_decoder.layer3.block.1.block.ReLU_2                  NaN  \n",
       "49_decoder.layer4.block.0.block.Conv2d_0       4.586471e+09  \n",
       "50_decoder.layer4.block.0.block.BatchNorm2d_1  3.200000e+01  \n",
       "51_decoder.layer4.block.0.block.ReLU_2                  NaN  \n",
       "52_decoder.layer4.block.1.block.Conv2d_0       7.644119e+08  \n",
       "53_decoder.layer4.block.1.block.BatchNorm2d_1  3.200000e+01  \n",
       "54_decoder.layer4.block.1.block.ReLU_2                  NaN  \n",
       "55_decoder.layer5.block.0.block.Conv2d_0       1.528824e+09  \n",
       "56_decoder.layer5.block.0.block.BatchNorm2d_1  1.600000e+01  \n",
       "57_decoder.layer5.block.0.block.ReLU_2                  NaN  \n",
       "58_decoder.layer5.block.1.block.Conv2d_0       7.644119e+08  \n",
       "59_decoder.layer5.block.1.block.BatchNorm2d_1  1.600000e+01  \n",
       "60_decoder.layer5.block.1.block.ReLU_2                  NaN  \n",
       "61_decoder.Conv2d_final_conv                   8.493466e+07  \n",
       "\n",
       "[62 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = deeplabv3_resnet101(pretrained=False, progress=True, num_classes=16, aux_loss=None)\n",
    "# #  导入模型与权重\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights='imagenet', \n",
    "    classes=16, \n",
    "    activation='softmax',\n",
    ")\n",
    "\n",
    "summary(model.to(device),  torch.zeros(3, 3, 576,576).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 随机数与数据读取、训练与验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.3.1 随机数设定\n",
    "warnings.filterwarnings('ignore')\n",
    "random.seed(13)\n",
    "np.random.seed(13)\n",
    "torch.manual_seed(13)\n",
    "torch.cuda.manual_seed_all(13)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "### 4.3.2 数据读取class\n",
    "class Dataset(Dataset):\n",
    "    \"\"\"My Dataset. Read images, apply augmentation and preprocessing transformations.\n",
    "    \n",
    "    Args:\n",
    "        images(numpy): image-npy(需要提前读入)\n",
    "        masks (numpy): mask-npy(需要提前读入)\n",
    "        class_values (list): values of classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline \n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing \n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "    \n",
    "    \"\"\"  \n",
    "    def __init__(self, images, masks, size, augmentation=None, preprocessing=None, mode = 'train'):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.size = size\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        # read data\n",
    "        image = self.images[i]\n",
    "        image = torch.from_numpy(image)\n",
    "        image = image.permute(2, 0, 1).float()\n",
    "        if self.mode == 'test':\n",
    "            mask = '0'\n",
    "        else:\n",
    "            mask = self.masks[i]   \n",
    "            mask = torch.from_numpy(mask)\n",
    "            # mask = mask.permute(2, 0, 1).float()\n",
    "\n",
    "            # apply augmentations\n",
    "            if self.augmentation:\n",
    "                sample = self.augmentation(image=image, mask=mask)\n",
    "                image, mask = sample['image'], sample['mask']\n",
    "\n",
    "            # apply preprocessing\n",
    "            if self.preprocessing:\n",
    "                sample = self.preprocessing(image=image, mask=mask)\n",
    "                image, mask = sample['image'], sample['mask']\n",
    "\n",
    "            # image = T.Compose([T.ToPILImage(),T.ToTensor()])(image) \n",
    "            # mask = mask.astype(np.uint8)\n",
    "            # mask = T.Compose([T.ToPILImage(),T.ToTensor()])(mask)    \n",
    "        \n",
    "        return image, mask #.transpose(2,0,1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)          \n",
    "\n",
    "    def augumentor(self,image):\n",
    "        # 数据增强使用了imgaug\n",
    "        '''未完善，不可使用\n",
    "        augment_img = iaa.Sequential([\n",
    "            iaa.Fliplr(0.5),\n",
    "            iaa.Flipud(0.5),\n",
    "            iaa.SomeOf((0,4),[\n",
    "                iaa.Affine(rotate=90),\n",
    "                iaa.Affine(rotate=180),\n",
    "                iaa.Affine(rotate=270),\n",
    "                iaa.Affine(shear=(-16, 16)),\n",
    "            ]),\n",
    "            iaa.OneOf([\n",
    "                    iaa.GaussianBlur((0, 3.0)), # blur images with a sigma between 0 and 3.0\n",
    "                    iaa.AverageBlur(k=(2, 7)), # blur image using local means with kernel sizes between 2 and 7\n",
    "                    iaa.MedianBlur(k=(3, 11)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "                ]),\n",
    "            #iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\n",
    "            ], random_order=True)\n",
    "        '''\n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug\n",
    "\n",
    "### 4.3.3 训练过程函数\n",
    "def train(train_loader,model,criterion,optimizer,w,h):\n",
    "    losses = AverageMeter()\n",
    "    acc, jaccard, f1, f1_macro = AverageMeter(), AverageMeter(), AverageMeter(), AverageMeter()\n",
    "    start = timer()\n",
    "    model.train()\n",
    "    for i,(image, mask) in enumerate(train_loader):\n",
    "        image = image.to(device)\n",
    "        b = image.size(0)\n",
    "        mask = torch.from_numpy(np.array(mask)).long().to(device)\n",
    "        # compute output\n",
    "        output = model(image)\n",
    "        loss = criterion(output, mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # print(loss.item())\n",
    "        # total_loss += loss.item()\n",
    "        losses.update(loss.item())\n",
    "        # 计算评测指标并更新 metrics\n",
    "        true = mask.cpu().data.numpy().reshape((b*w*h,1))\n",
    "        pred = np.argmax(F.softmax(output).cpu().data.numpy(),axis=1).reshape((b*w*h,1))\n",
    "        acc_score = accuracy_score(true, pred)\n",
    "        #jaccard_batch = jaccard_score(true, pred, average='weighted')\n",
    "        #f1_batch = f1_score(true, pred, average='weighted')\n",
    "        #f1_batch_macro = f1_score(true, pred, average='macro')\n",
    "        # kappa.update(kappa_score)\n",
    "        acc.update(acc_score)\n",
    "        #jaccard.update(jaccard_batch)\n",
    "        #f1.update(f1_batch)\n",
    "        #f1_macro.update(f1_batch_macro)\n",
    "        \n",
    "        print('\\r',end='',flush=True)\n",
    "        message = '%03d/%03d, %s\\t===== loss:%0.5f, acc:%0.5f'%( #IoU:%0.5f, F1:%0.5f, F1-macro:%0.5f' % (\n",
    "                  i, len(train_loader), time_to_str((timer() - start),'int'),\n",
    "                  losses.avg, acc.avg)   #, jaccard.avg, f1.avg, f1_macro.avg ) \n",
    "        print(message, end='',flush=True)\n",
    "        \n",
    "    #log.write(\"\\n\")\n",
    "    log.write(message)\n",
    "    log.write(\"\\n\")\n",
    "    return [losses.avg, acc.avg, jaccard.avg, f1.avg, f1_macro.avg]\n",
    "\n",
    "# 4.3.4 验证过程函数\n",
    "def evaluate(val_loader, model, criterion, w,h):\n",
    "    losses = AverageMeter()\n",
    "    kappa, acc, jaccard = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "    # switch mode for evaluation\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (image,mask) in enumerate(val_loader):\n",
    "            image_var = image.to(device)\n",
    "            b = image_var.size(0) \n",
    "            mask = torch.from_numpy(np.array(mask)).long().to(device)\n",
    "            # 计算loss\n",
    "            output = model(image_var)\n",
    "            loss = criterion(output, mask)\n",
    "            losses.update(loss.item())\n",
    "            # 计算评测指标并更新 metrics\n",
    "            true = mask.cpu().data.numpy().reshape((b*w*h,1))\n",
    "            pred = np.argmax(F.softmax(output).cpu().data.numpy(),axis=1).reshape((b*w*h,1))\n",
    "            kappa_score = cohen_kappa_score(true, pred)\n",
    "            acc_score = accuracy_score(true, pred)\n",
    "            jaccard_batch = jaccard_score(true, pred, average='weighted')\n",
    "            #f1_batch = f1_score(true, pred, average='weighted')\n",
    "            #f1_batch_macro = f1_score(true, pred, average='macro')\n",
    "            kappa.update(kappa_score)\n",
    "            acc.update(acc_score)\n",
    "            jaccard.update(jaccard_batch)\n",
    "            #f1.update(f1_batch)\n",
    "            #f1_macro.update(f1_batch_macro)\n",
    "            print('\\r',end='',flush=True)\n",
    "            message = '\\t\\t=val= loss:%0.5f, kappa:%0.5f, acc:%0.5f, IoU:%0.5f'%( \\\n",
    "                            #, F1:%0.5f, F1-macro:%0.5f' % (\\\n",
    "                          losses.avg, kappa.avg, acc.avg, jaccard.avg) #, f1.avg, f1_macro.avg )\n",
    "            print(message, end='',flush=True)\n",
    "        #log.write(\"\\n\")\n",
    "        log.write(message)\n",
    "        log.write(\"\\n\")\n",
    "\n",
    "    return [losses.avg, kappa.avg, acc.avg, jaccard.avg] #, f1.avg, f1_macro.avg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3960, 576, 576, 4) (3960, 576, 576)\n",
      "(1560, 576, 576, 4) (1560, 576, 576)\n"
     ]
    }
   ],
   "source": [
    "train_npy = np.load(\"../data/train_1106.npy\")\n",
    "train_mask = np.load(\"../data/labels_1106.npy\")\n",
    "print(train_npy.shape, train_mask.shape)\n",
    "\n",
    "val_npy = np.load(\"../data/test_1106.npy\")\n",
    "val_mask = np.load(\"../data/test_labels_1106.npy\")\n",
    "print(val_npy.shape, val_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3960, 576, 576, 3) (3960, 576, 576)\n"
     ]
    }
   ],
   "source": [
    "# 本代码使用三通道\n",
    "train_npy,val_npy = train_npy[:,:,:,1:4],val_npy[:,:,:,1:4]\n",
    "print(train_npy.shape, train_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "    train_npy,\n",
    "    train_mask, \n",
    "    size = SIZE,\n",
    "    augmentation=None, #get_training_augmentation(), \n",
    "    preprocessing=None, #get_preprocessing(preprocessing_fn), #None\n",
    ")\n",
    "\n",
    "valid_dataset = Dataset(\n",
    "    val_npy,\n",
    "    val_mask,\n",
    "    size = SIZE,\n",
    "    augmentation=None, #get_training_augmentation(), \n",
    "    preprocessing=None, #get_preprocessing(preprocessing_fn), #None\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BS*2, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\t400 epoches\n",
      "Epoch: 16\t======== 开始时间 19-11-08 18:22:07 ========\n",
      "098/099, 259s\t===== loss:0.25256, acc:0.91126\n",
      "\t\t=val= loss:0.95849, kappa:0.56846, acc:0.71671, IoU:0.58440\n",
      "Epoch: 17\t======== 开始时间 19-11-08 18:33:44 ========\n",
      "098/099, 250s\t===== loss:0.24018, acc:0.91622\n",
      "\t\t=val= loss:1.22709, kappa:0.48580, acc:0.64793, IoU:0.51532\n",
      "Epoch: 18\t======== 开始时间 19-11-08 18:44:49 ========\n",
      "098/099, 248s\t===== loss:0.20976, acc:0.92540\n",
      "\t\t=val= loss:0.93765, kappa:0.58704, acc:0.73419, IoU:0.60118\n",
      "==Get best ACC in epoch 18: 0.73418539\n",
      "==Get best IoU in epoch 18: 0.60118020\n",
      "Epoch: 19\t======== 开始时间 19-11-08 18:55:58 ========\n",
      "098/099, 248s\t===== loss:0.18223, acc:0.93438\n",
      "\t\t=val= loss:1.09026, kappa:0.52544, acc:0.68172, IoU:0.55433\n",
      "Epoch: 20\t======== 开始时间 19-11-08 19:07:05 ========\n",
      "098/099, 247s\t===== loss:0.21561, acc:0.92401\n",
      "\t\t=val= loss:1.73926, kappa:0.42373, acc:0.61511, IoU:0.48030\n",
      "Epoch: 21\t======== 开始时间 19-11-08 19:18:16 ========\n",
      "098/099, 248s\t===== loss:0.28799, acc:0.90000\n",
      "\t\t=val= loss:1.03082, kappa:0.57049, acc:0.71905, IoU:0.59123\n",
      "Epoch: 22\t======== 开始时间 19-11-08 19:29:30 ========\n",
      "098/099, 248s\t===== loss:0.16429, acc:0.94053\n",
      "\t\t=val= loss:1.04416, kappa:0.58823, acc:0.73686, IoU:0.60538\n",
      "==Get best ACC in epoch 22: 0.73686438\n",
      "==Get best IoU in epoch 22: 0.60537656\n",
      "Epoch: 23\t======== 开始时间 19-11-08 19:40:56 ========\n",
      "098/099, 248s\t===== loss:0.14890, acc:0.94559\n",
      "\t\t=val= loss:1.06002, kappa:0.58069, acc:0.72257, IoU:0.59600\n",
      "Epoch: 24\t======== 开始时间 19-11-08 19:52:07 ========\n",
      "098/099, 248s\t===== loss:0.13251, acc:0.95156\n",
      "\t\t=val= loss:1.24981, kappa:0.54100, acc:0.69582, IoU:0.55565\n",
      "Epoch: 25\t======== 开始时间 19-11-08 20:03:21 ========\n",
      "098/099, 248s\t===== loss:0.13266, acc:0.95135\n",
      "\t\t=val= loss:1.19838, kappa:0.56126, acc:0.71692, IoU:0.58179\n",
      "Epoch: 26\t======== 开始时间 19-11-08 20:14:37 ========\n",
      "098/099, 248s\t===== loss:0.18977, acc:0.93259\n",
      "\t\t=val= loss:1.14480, kappa:0.51876, acc:0.67849, IoU:0.54753\n",
      "Epoch: 27\t======== 开始时间 19-11-08 20:25:53 ========\n",
      "098/099, 248s\t===== loss:0.28231, acc:0.90280\n",
      "\t\t=val= loss:1.43115, kappa:0.50981, acc:0.67406, IoU:0.53593\n",
      "降低学习率至0.0005000000,重新载入模型\n",
      "Epoch: 28\t======== 开始时间 19-11-08 20:37:05 ========\n",
      "098/099, 248s\t===== loss:0.19589, acc:0.93093\n",
      "\t\t=val= loss:0.95313, kappa:0.57926, acc:0.72357, IoU:0.59372\n",
      "Epoch: 29\t======== 开始时间 19-11-08 20:48:20 ========\n",
      "098/099, 248s\t===== loss:0.17223, acc:0.93881\n",
      "\t\t=val= loss:1.07108, kappa:0.56143, acc:0.70708, IoU:0.57507\n",
      "Epoch: 30\t======== 开始时间 19-11-08 20:59:36 ========\n",
      "098/099, 247s\t===== loss:0.16241, acc:0.94204\n",
      "\t\t=val= loss:1.11288, kappa:0.55261, acc:0.70278, IoU:0.56398\n",
      "Epoch: 31\t======== 开始时间 19-11-08 21:10:46 ========\n",
      "098/099, 248s\t===== loss:0.14554, acc:0.94792\n",
      "\t\t=val= loss:1.03906, kappa:0.58794, acc:0.73396, IoU:0.59803\n",
      "Epoch: 32\t======== 开始时间 19-11-08 21:21:54 ========\n",
      "098/099, 248s\t===== loss:0.15023, acc:0.94572\n",
      "\t\t=val= loss:1.41843, kappa:0.49834, acc:0.67303, IoU:0.52294\n",
      "降低学习率至0.0002500000,重新载入模型\n",
      "Epoch: 33\t======== 开始时间 19-11-08 21:33:08 ========\n",
      "098/099, 248s\t===== loss:0.17852, acc:0.93711\n",
      "\t\t=val= loss:0.94253, kappa:0.58581, acc:0.73016, IoU:0.59816\n",
      "Epoch: 34\t======== 开始时间 19-11-08 21:44:18 ========\n",
      "098/099, 246s\t===== loss:0.15766, acc:0.94461\n",
      "\t\t=val= loss:0.95990, kappa:0.58913, acc:0.73263, IoU:0.60319\n",
      "Epoch: 35\t======== 开始时间 19-11-08 21:55:38 ========\n",
      "098/099, 249s\t===== loss:0.14591, acc:0.94835\n",
      "\t\t=val= loss:0.92925, kappa:0.59386, acc:0.73461, IoU:0.60602\n",
      "==Get best IoU in epoch 35: 0.60601661\n",
      "Epoch: 36\t======== 开始时间 19-11-08 22:06:53 ========\n",
      "098/099, 248s\t===== loss:0.13696, acc:0.95133\n",
      "\t\t=val= loss:0.95474, kappa:0.59861, acc:0.73773, IoU:0.61062\n",
      "==Get best ACC in epoch 36: 0.73773062\n",
      "==Get best IoU in epoch 36: 0.61061997\n",
      "Epoch: 37\t======== 开始时间 19-11-08 22:18:15 ========\n",
      "098/099, 247s\t===== loss:0.12741, acc:0.95440\n",
      "\t\t=val= loss:1.08982, kappa:0.57918, acc:0.72493, IoU:0.59072\n",
      "Epoch: 38\t======== 开始时间 19-11-08 22:29:24 ========\n",
      "098/099, 248s\t===== loss:0.11557, acc:0.95855\n",
      "\t\t=val= loss:1.10269, kappa:0.58005, acc:0.72683, IoU:0.59410\n",
      "Epoch: 39\t======== 开始时间 19-11-08 22:40:41 ========\n",
      "098/099, 247s\t===== loss:0.12482, acc:0.95534\n",
      "\t\t=val= loss:1.10288, kappa:0.58774, acc:0.73129, IoU:0.59962\n",
      "Epoch: 40\t======== 开始时间 19-11-08 22:51:48 ========\n",
      "098/099, 248s\t===== loss:0.13572, acc:0.95183\n",
      "\t\t=val= loss:1.02983, kappa:0.59680, acc:0.74043, IoU:0.61105\n",
      "==Get best ACC in epoch 40: 0.74043186\n",
      "==Get best IoU in epoch 40: 0.61104502\n",
      "Epoch: 41\t======== 开始时间 19-11-08 23:03:09 ========\n",
      "098/099, 247s\t===== loss:0.10313, acc:0.96250\n",
      "\t\t=val= loss:1.08543, kappa:0.59242, acc:0.73537, IoU:0.60382\n",
      "Epoch: 42\t======== 开始时间 19-11-08 23:14:20 ========\n",
      "098/099, 248s\t===== loss:0.09129, acc:0.96671\n",
      "\t\t=val= loss:1.12397, kappa:0.59132, acc:0.73447, IoU:0.60444\n",
      "Epoch: 43\t======== 开始时间 19-11-08 23:25:36 ========\n",
      "098/099, 248s\t===== loss:0.09905, acc:0.96408\n",
      "\t\t=val= loss:1.11393, kappa:0.58687, acc:0.72757, IoU:0.60341\n",
      "Epoch: 44\t======== 开始时间 19-11-08 23:36:50 ========\n",
      "098/099, 248s\t===== loss:0.09362, acc:0.96582\n",
      "\t\t=val= loss:1.13538, kappa:0.59337, acc:0.73517, IoU:0.60644\n",
      "Epoch: 45\t======== 开始时间 19-11-08 23:47:57 ========\n",
      "098/099, 248s\t===== loss:0.08197, acc:0.96967\n",
      "\t\t=val= loss:1.14358, kappa:0.59777, acc:0.74073, IoU:0.61057\n",
      "==Get best ACC in epoch 45: 0.74073092\n",
      "Epoch: 46\t======== 开始时间 19-11-08 23:59:14 ========\n",
      "098/099, 248s\t===== loss:0.08090, acc:0.96998\n",
      "\t\t=val= loss:1.17139, kappa:0.59919, acc:0.73888, IoU:0.61083\n",
      "Epoch: 47\t======== 开始时间 19-11-09 00:10:34 ========\n",
      "098/099, 248s\t===== loss:0.07682, acc:0.97149\n",
      "\t\t=val= loss:1.21714, kappa:0.59196, acc:0.73602, IoU:0.60571\n",
      "Epoch: 48\t======== 开始时间 19-11-09 00:21:50 ========\n",
      "098/099, 248s\t===== loss:0.07315, acc:0.97283\n",
      "\t\t=val= loss:1.20857, kappa:0.59432, acc:0.73589, IoU:0.60812\n",
      "Epoch: 49\t======== 开始时间 19-11-09 00:33:06 ========\n",
      "098/099, 249s\t===== loss:0.07647, acc:0.97152\n",
      "\t\t=val= loss:1.14578, kappa:0.59788, acc:0.73678, IoU:0.61141\n",
      "==Get best IoU in epoch 49: 0.61141017\n",
      "Epoch: 50\t======== 开始时间 19-11-09 00:44:26 ========\n",
      "098/099, 247s\t===== loss:0.06813, acc:0.97457\n",
      "\t\t=val= loss:1.28376, kappa:0.57652, acc:0.72396, IoU:0.59494\n",
      "Epoch: 51\t======== 开始时间 19-11-09 00:55:41 ========\n",
      "098/099, 248s\t===== loss:0.06692, acc:0.97483\n",
      "\t\t=val= loss:1.24713, kappa:0.59519, acc:0.73526, IoU:0.60766\n",
      "Epoch: 52\t======== 开始时间 19-11-09 01:06:52 ========\n",
      "098/099, 248s\t===== loss:0.07488, acc:0.97245\n",
      "\t\t=val= loss:1.24974, kappa:0.58329, acc:0.73143, IoU:0.59942\n",
      "Epoch: 53\t======== 开始时间 19-11-09 01:18:01 ========\n",
      "098/099, 248s\t===== loss:0.11466, acc:0.95959\n",
      "\t\t=val= loss:1.22258, kappa:0.55755, acc:0.70830, IoU:0.57455\n",
      "Epoch: 54\t======== 开始时间 19-11-09 01:29:10 ========\n",
      "098/099, 247s\t===== loss:0.13534, acc:0.95164\n",
      "\t\t=val= loss:1.14020, kappa:0.58152, acc:0.72769, IoU:0.59605\n",
      "降低学习率至0.0001250000,重新载入模型\n",
      "Epoch: 55\t======== 开始时间 19-11-09 01:40:26 ========\n",
      "098/099, 248s\t===== loss:0.17271, acc:0.93939\n",
      "\t\t=val= loss:0.94047, kappa:0.58963, acc:0.73316, IoU:0.60392\n",
      "Epoch: 56\t======== 开始时间 19-11-09 01:51:42 ========\n",
      "098/099, 248s\t===== loss:0.15909, acc:0.94409\n",
      "\t\t=val= loss:0.89821, kappa:0.59935, acc:0.74118, IoU:0.61152\n",
      "==Get best ACC in epoch 56: 0.74118128\n",
      "==Get best IoU in epoch 56: 0.61151877\n",
      "Epoch: 57\t======== 开始时间 19-11-09 02:03:03 ========\n",
      "098/099, 248s\t===== loss:0.14563, acc:0.94903\n",
      "\t\t=val= loss:0.96851, kappa:0.59185, acc:0.73477, IoU:0.60600\n",
      "Epoch: 58\t======== 开始时间 19-11-09 02:14:26 ========\n",
      "098/099, 248s\t===== loss:0.13697, acc:0.95206\n",
      "\t\t=val= loss:0.92290, kappa:0.60052, acc:0.73964, IoU:0.61355\n",
      "==Get best IoU in epoch 58: 0.61355187\n",
      "Epoch: 59\t======== 开始时间 19-11-09 02:25:42 ========\n",
      "098/099, 246s\t===== loss:0.13014, acc:0.95435\n",
      "\t\t=val= loss:0.99515, kappa:0.58435, acc:0.72500, IoU:0.59634\n",
      "Epoch: 60\t======== 开始时间 19-11-09 02:36:56 ========\n",
      "098/099, 248s\t===== loss:0.12138, acc:0.95712\n",
      "\t\t=val= loss:0.99117, kappa:0.59463, acc:0.73669, IoU:0.60827\n",
      "Epoch: 61\t======== 开始时间 19-11-09 02:48:15 ========\n",
      "098/099, 248s\t===== loss:0.11147, acc:0.96053\n",
      "\t\t=val= loss:1.00193, kappa:0.59645, acc:0.73925, IoU:0.61004\n",
      "Epoch: 62\t======== 开始时间 19-11-09 02:59:27 ========\n",
      "098/099, 248s\t===== loss:0.10633, acc:0.96216\n",
      "\t\t=val= loss:1.03615, kappa:0.60601, acc:0.74566, IoU:0.61523\n",
      "==Get best ACC in epoch 62: 0.74566430\n",
      "==Get best IoU in epoch 62: 0.61523179\n",
      "Epoch: 63\t======== 开始时间 19-11-09 03:10:43 ========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "098/099, 248s\t===== loss:0.10132, acc:0.96402\n",
      "\t\t=val= loss:1.02101, kappa:0.60187, acc:0.74073, IoU:0.61499\n",
      "Epoch: 64\t======== 开始时间 19-11-09 03:21:55 ========\n",
      "098/099, 248s\t===== loss:0.09254, acc:0.96690\n",
      "\t\t=val= loss:1.06421, kappa:0.59660, acc:0.73822, IoU:0.60972\n",
      "Epoch: 65\t======== 开始时间 19-11-09 03:33:12 ========\n",
      "098/099, 248s\t===== loss:0.08868, acc:0.96826\n",
      "\t\t=val= loss:1.08964, kappa:0.59513, acc:0.73779, IoU:0.60920\n",
      "Epoch: 66\t======== 开始时间 19-11-09 03:44:29 ========\n",
      "098/099, 248s\t===== loss:0.08701, acc:0.96885\n",
      "\t\t=val= loss:1.11518, kappa:0.58802, acc:0.73154, IoU:0.60047\n",
      "Epoch: 67\t======== 开始时间 19-11-09 03:55:46 ========\n",
      "098/099, 248s\t===== loss:0.08214, acc:0.97033\n",
      "\t\t=val= loss:1.14955, kappa:0.58917, acc:0.73309, IoU:0.60386\n",
      "降低学习率至0.0000625000,重新载入模型\n",
      "Epoch: 68\t======== 开始时间 19-11-09 04:06:56 ========\n",
      "098/099, 246s\t===== loss:0.17409, acc:0.93893\n",
      "\t\t=val= loss:0.87558, kappa:0.59789, acc:0.73841, IoU:0.60935\n",
      "Epoch: 69\t======== 开始时间 19-11-09 04:18:15 ========\n",
      "098/099, 248s\t===== loss:0.16025, acc:0.94425\n",
      "\t\t=val= loss:0.91214, kappa:0.59650, acc:0.73825, IoU:0.60892\n",
      "Epoch: 70\t======== 开始时间 19-11-09 04:29:34 ========\n",
      "098/099, 248s\t===== loss:0.15164, acc:0.94726\n",
      "\t\t=val= loss:0.91177, kappa:0.59477, acc:0.73687, IoU:0.60777\n",
      "Epoch: 71\t======== 开始时间 19-11-09 04:40:50 ========\n",
      "098/099, 247s\t===== loss:0.14448, acc:0.94985\n",
      "\t\t=val= loss:0.93674, kappa:0.59542, acc:0.73676, IoU:0.60848\n",
      "Epoch: 72\t======== 开始时间 19-11-09 04:52:00 ========\n",
      "098/099, 248s\t===== loss:0.14009, acc:0.95140\n",
      "\t\t=val= loss:0.94882, kappa:0.59204, acc:0.73517, IoU:0.60585\n",
      "降低学习率至0.0000312500,重新载入模型\n",
      "Epoch: 73\t======== 开始时间 19-11-09 05:03:17 ========\n",
      "098/099, 249s\t===== loss:0.17584, acc:0.93812\n",
      "\t\t=val= loss:0.90750, kappa:0.59264, acc:0.73584, IoU:0.60579\n",
      "Epoch: 74\t======== 开始时间 19-11-09 05:14:34 ========\n",
      "098/099, 247s\t===== loss:0.16591, acc:0.94191\n",
      "\t\t=val= loss:0.89141, kappa:0.59462, acc:0.73626, IoU:0.60635\n",
      "Epoch: 75\t======== 开始时间 19-11-09 05:25:54 ========\n",
      "098/099, 248s\t===== loss:0.15879, acc:0.94462\n",
      "\t\t=val= loss:0.90443, kappa:0.59607, acc:0.73726, IoU:0.60849\n",
      "Epoch: 76\t======== 开始时间 19-11-09 05:37:16 ========\n",
      "098/099, 248s\t===== loss:0.15441, acc:0.94622\n",
      "\t\t=val= loss:0.90855, kappa:0.59498, acc:0.73599, IoU:0.60656\n",
      "Epoch: 77\t======== 开始时间 19-11-09 05:48:31 ========\n",
      "098/099, 248s\t===== loss:0.15057, acc:0.94775\n",
      "\t\t=val= loss:0.90368, kappa:0.59673, acc:0.73888, IoU:0.60859\n",
      "降低学习率至0.0000156250,重新载入模型\n",
      "Epoch: 78\t======== 开始时间 19-11-09 05:59:51 ========\n",
      "098/099, 248s\t===== loss:0.17946, acc:0.93668\n",
      "\t\t=val= loss:0.89539, kappa:0.59739, acc:0.73784, IoU:0.60918\n",
      "Epoch: 79\t======== 开始时间 19-11-09 06:11:09 ========\n",
      "098/099, 248s\t===== loss:0.17205, acc:0.93957\n",
      "\t\t=val= loss:0.88997, kappa:0.59788, acc:0.73918, IoU:0.60996\n",
      "Epoch: 80\t======== 开始时间 19-11-09 06:22:18 ========\n",
      "098/099, 248s\t===== loss:0.16737, acc:0.94141\n",
      "\t\t=val= loss:0.89929, kappa:0.59649, acc:0.73822, IoU:0.60865\n",
      "Epoch: 81\t======== 开始时间 19-11-09 06:33:30 ========\n",
      "098/099, 248s\t===== loss:0.16308, acc:0.94297\n",
      "\t\t=val= loss:0.89702, kappa:0.59683, acc:0.73861, IoU:0.60928\n",
      "Epoch: 82\t======== 开始时间 19-11-09 06:44:48 ========\n",
      "098/099, 249s\t===== loss:0.16071, acc:0.94418\n",
      "\t\t=val= loss:0.89336, kappa:0.59822, acc:0.73853, IoU:0.60981\n",
      "降低学习率至0.0000078125,重新载入模型\n",
      "Epoch: 83\t======== 开始时间 19-11-09 06:56:06 ========\n",
      "098/099, 248s\t===== loss:0.18438, acc:0.93514\n",
      "\t\t=val= loss:0.89239, kappa:0.59581, acc:0.73682, IoU:0.60800\n",
      "Epoch: 84\t======== 开始时间 19-11-09 07:07:20 ========\n",
      "098/099, 248s\t===== loss:0.17693, acc:0.93779\n",
      "\t\t=val= loss:0.90552, kappa:0.59468, acc:0.73590, IoU:0.60665\n",
      "Epoch: 85\t======== 开始时间 19-11-09 07:18:34 ========\n",
      "098/099, 250s\t===== loss:0.17138, acc:0.93977\n",
      "\t\t=val= loss:0.88840, kappa:0.59843, acc:0.73888, IoU:0.61032\n",
      "Epoch: 86\t======== 开始时间 19-11-09 07:29:54 ========\n",
      "098/099, 248s\t===== loss:0.16838, acc:0.94073\n",
      "\t\t=val= loss:0.89309, kappa:0.59627, acc:0.73722, IoU:0.60761\n",
      "Epoch: 87\t======== 开始时间 19-11-09 07:41:12 ========\n",
      "098/099, 249s\t===== loss:0.16895, acc:0.94100\n",
      "\t\t=val= loss:0.88615, kappa:0.59694, acc:0.73796, IoU:0.60888\n",
      "降低学习率至0.0000039063,重新载入模型\n",
      "Epoch: 88\t======== 开始时间 19-11-09 07:52:30 ========\n",
      "098/099, 249s\t===== loss:0.18699, acc:0.93394\n",
      "\t\t=val= loss:0.88994, kappa:0.59546, acc:0.73664, IoU:0.60706\n",
      "Epoch: 89\t======== 开始时间 19-11-09 08:03:49 ========\n",
      "098/099, 248s\t===== loss:0.17923, acc:0.93701\n",
      "\t\t=val= loss:0.88305, kappa:0.59816, acc:0.73872, IoU:0.61052\n",
      "Epoch: 90\t======== 开始时间 19-11-09 08:15:08 ========\n",
      "098/099, 248s\t===== loss:0.17601, acc:0.93814\n",
      "\t\t=val= loss:0.90437, kappa:0.59325, acc:0.73521, IoU:0.60541\n",
      "Epoch: 91\t======== 开始时间 19-11-09 08:26:24 ========\n",
      "098/099, 248s\t===== loss:0.17515, acc:0.93845\n",
      "\t\t=val= loss:0.90170, kappa:0.59564, acc:0.73717, IoU:0.60833\n",
      "Epoch: 92\t======== 开始时间 19-11-09 08:37:37 ========\n",
      "098/099, 248s\t===== loss:0.17420, acc:0.93885\n",
      "\t\t=val= loss:0.88070, kappa:0.59802, acc:0.73808, IoU:0.60946\n",
      "降低学习率至0.0000019531,重新载入模型\n",
      "Epoch: 93\t======== 开始时间 19-11-09 08:48:53 ========\n",
      "098/099, 248s\t===== loss:0.19080, acc:0.93284\n",
      "\t\t=val= loss:0.90165, kappa:0.59396, acc:0.73638, IoU:0.60617\n",
      "Epoch: 94\t======== 开始时间 19-11-09 09:00:09 ========\n",
      "098/099, 248s\t===== loss:0.18462, acc:0.93499\n",
      "\t\t=val= loss:0.90547, kappa:0.59372, acc:0.73513, IoU:0.60585\n",
      "Epoch: 95\t======== 开始时间 19-11-09 09:11:27 ========\n",
      "098/099, 248s\t===== loss:0.18204, acc:0.93586\n",
      "\t\t=val= loss:0.89806, kappa:0.59438, acc:0.73603, IoU:0.60671\n",
      "Epoch: 96\t======== 开始时间 19-11-09 09:22:44 ========\n",
      "098/099, 248s\t===== loss:0.17902, acc:0.93712\n",
      "\t\t=val= loss:0.90157, kappa:0.59465, acc:0.73616, IoU:0.60701\n",
      "Epoch: 97\t======== 开始时间 19-11-09 09:34:05 ========\n",
      "098/099, 249s\t===== loss:0.17681, acc:0.93779\n",
      "\t\t=val= loss:0.89642, kappa:0.59627, acc:0.73843, IoU:0.60895\n",
      "降低学习率至0.0000009766,重新载入模型\n",
      "Epoch: 98\t======== 开始时间 19-11-09 09:45:25 ========\n",
      "098/099, 248s\t===== loss:0.19296, acc:0.93204\n",
      "\t\t=val= loss:0.91444, kappa:0.59163, acc:0.73413, IoU:0.60413\n",
      "Epoch: 99\t======== 开始时间 19-11-09 09:56:44 ========\n",
      "098/099, 248s\t===== loss:0.18632, acc:0.93438\n",
      "\t\t=val= loss:0.91437, kappa:0.59193, acc:0.73444, IoU:0.60439\n",
      "Epoch: 100\t======== 开始时间 19-11-09 10:07:58 ========\n",
      "098/099, 248s\t===== loss:0.18727, acc:0.93401\n",
      "\t\t=val= loss:0.90329, kappa:0.59431, acc:0.73611, IoU:0.60665\n",
      "Epoch: 101\t======== 开始时间 19-11-09 10:19:16 ========\n",
      "098/099, 249s\t===== loss:0.18211, acc:0.93594\n",
      "\t\t=val= loss:0.89519, kappa:0.59478, acc:0.73650, IoU:0.60687\n",
      "Epoch: 102\t======== 开始时间 19-11-09 10:30:34 ========\n",
      "098/099, 249s\t===== loss:0.18278, acc:0.93584\n",
      "\t\t=val= loss:0.91545, kappa:0.59321, acc:0.73629, IoU:0.60663\n",
      "降低学习率至0.0000004883,重新载入模型\n",
      "Epoch: 103\t======== 开始时间 19-11-09 10:41:52 ========\n",
      "098/099, 248s\t===== loss:0.19202, acc:0.93218\n",
      "\t\t=val= loss:0.91853, kappa:0.59118, acc:0.73437, IoU:0.60387\n",
      "Epoch: 104\t======== 开始时间 19-11-09 10:53:06 ========\n",
      "098/099, 249s\t===== loss:0.18891, acc:0.93322\n",
      "\t\t=val= loss:0.90847, kappa:0.59053, acc:0.73302, IoU:0.60199\n",
      "Epoch: 105\t======== 开始时间 19-11-09 11:04:27 ========\n",
      "098/099, 251s\t===== loss:0.18842, acc:0.93384\n",
      "\t\t=val= loss:0.90954, kappa:0.59271, acc:0.73536, IoU:0.60516\n",
      "Epoch: 106\t======== 开始时间 19-11-09 11:15:53 ========\n",
      "098/099, 250s\t===== loss:0.18557, acc:0.93461\n",
      "\t\t=val= loss:0.90835, kappa:0.59276, acc:0.73457, IoU:0.60528\n",
      "Epoch: 107\t======== 开始时间 19-11-09 11:27:18 ========\n",
      "098/099, 251s\t===== loss:0.18290, acc:0.93555\n",
      "\t\t=val= loss:0.90676, kappa:0.59125, acc:0.73435, IoU:0.60329\n",
      "降低学习率至0.0000002441,重新载入模型\n",
      "Epoch: 108\t======== 开始时间 19-11-09 11:38:43 ========\n",
      "098/099, 250s\t===== loss:0.19411, acc:0.93130\n",
      "\t\t=val= loss:0.90804, kappa:0.59304, acc:0.73513, IoU:0.60538\n",
      "Epoch: 109\t======== 开始时间 19-11-09 11:50:07 ========\n",
      "098/099, 248s\t===== loss:0.19634, acc:0.93137\n",
      "\t\t=val= loss:0.91873, kappa:0.58978, acc:0.73310, IoU:0.60176\n",
      "Epoch: 110\t======== 开始时间 19-11-09 12:01:23 ========\n",
      "098/099, 247s\t===== loss:0.19181, acc:0.93228\n",
      "\t\t=val= loss:0.91676, kappa:0.59138, acc:0.73386, IoU:0.60365\n",
      "Epoch: 111\t======== 开始时间 19-11-09 12:12:40 ========\n",
      "098/099, 248s\t===== loss:0.19179, acc:0.93247\n",
      "\t\t=val= loss:0.91736, kappa:0.59065, acc:0.73450, IoU:0.60319\n",
      "Epoch: 112\t======== 开始时间 19-11-09 12:23:57 ========\n",
      "098/099, 249s\t===== loss:0.18686, acc:0.93401\n",
      "\t\t=val= loss:0.90483, kappa:0.59218, acc:0.73427, IoU:0.60374\n",
      "降低学习率至0.0000001221,重新载入模型\n",
      "Epoch: 113\t======== 开始时间 19-11-09 12:35:15 ========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "098/099, 249s\t===== loss:0.19648, acc:0.93072\n",
      "\t\t=val= loss:0.91251, kappa:0.58973, acc:0.73253, IoU:0.60172\n",
      "Epoch: 114\t======== 开始时间 19-11-09 12:46:32 ========\n",
      "098/099, 249s\t===== loss:0.19247, acc:0.93200\n",
      "\t\t=val= loss:0.91873, kappa:0.59008, acc:0.73181, IoU:0.60198\n",
      "Epoch: 115\t======== 开始时间 19-11-09 12:57:53 ========\n",
      "098/099, 247s\t===== loss:0.19296, acc:0.93188\n",
      "\t\t=val= loss:0.90699, kappa:0.59340, acc:0.73643, IoU:0.60610\n",
      "Epoch: 116\t======== 开始时间 19-11-09 13:09:07 ========\n",
      "098/099, 249s\t===== loss:0.19306, acc:0.93172\n",
      "\t\t=val= loss:0.91579, kappa:0.59050, acc:0.73319, IoU:0.60244\n",
      "Epoch: 117\t======== 开始时间 19-11-09 13:20:25 ========\n",
      "098/099, 249s\t===== loss:0.18962, acc:0.93287\n",
      "\t\t=val= loss:0.92604, kappa:0.58988, acc:0.73350, IoU:0.60264\n",
      "降低学习率至0.0000000610,重新载入模型\n",
      "Epoch: 118\t======== 开始时间 19-11-09 13:31:45 ========\n",
      "098/099, 248s\t===== loss:0.19448, acc:0.93135\n",
      "\t\t=val= loss:0.92769, kappa:0.58906, acc:0.73326, IoU:0.60152\n",
      "Epoch: 119\t======== 开始时间 19-11-09 13:43:05 ========\n",
      "098/099, 248s\t===== loss:0.19118, acc:0.93232\n",
      "\t\t=val= loss:0.91225, kappa:0.58910, acc:0.73202, IoU:0.60025\n",
      "Epoch: 120\t======== 开始时间 19-11-09 13:54:13 ========\n",
      "098/099, 247s\t===== loss:0.19409, acc:0.93167\n",
      "\t\t=val= loss:0.91200, kappa:0.59143, acc:0.73366, IoU:0.60367\n",
      "Epoch: 121\t======== 开始时间 19-11-09 14:05:29 ========\n",
      "098/099, 248s\t===== loss:0.19362, acc:0.93161\n",
      "\t\t=val= loss:0.91420, kappa:0.58992, acc:0.73291, IoU:0.60199\n",
      "Epoch: 122\t======== 开始时间 19-11-09 14:16:45 ========\n",
      "098/099, 249s\t===== loss:0.19312, acc:0.93156\n",
      "\t\t=val= loss:0.92360, kappa:0.58919, acc:0.73230, IoU:0.60135\n",
      "降低学习率至0.0000000305,重新载入模型\n",
      "Epoch: 123\t======== 开始时间 19-11-09 14:27:57 ========\n",
      "098/099, 247s\t===== loss:0.19669, acc:0.93079\n",
      "\t\t=val= loss:0.92058, kappa:0.58801, acc:0.73130, IoU:0.59949\n",
      "Epoch: 124\t======== 开始时间 19-11-09 14:39:09 ========\n",
      "098/099, 249s\t===== loss:0.19374, acc:0.93165\n",
      "\t\t=val= loss:0.91237, kappa:0.59250, acc:0.73484, IoU:0.60456\n",
      "Epoch: 125\t======== 开始时间 19-11-09 14:50:30 ========\n",
      "098/099, 248s\t===== loss:0.19329, acc:0.93175\n",
      "\t\t=val= loss:0.90297, kappa:0.59247, acc:0.73490, IoU:0.60450\n",
      "Epoch: 126\t======== 开始时间 19-11-09 15:01:47 ========\n",
      "098/099, 249s\t===== loss:0.19510, acc:0.93137\n",
      "\t\t=val= loss:0.91532, kappa:0.59267, acc:0.73544, IoU:0.60518\n",
      "Epoch: 127\t======== 开始时间 19-11-09 15:13:06 ========\n",
      "098/099, 249s\t===== loss:0.19354, acc:0.93156\n",
      "\t\t=val= loss:0.92199, kappa:0.59086, acc:0.73426, IoU:0.60332\n",
      "降低学习率至0.0000000153,重新载入模型\n",
      "Epoch: 128\t======== 开始时间 19-11-09 15:24:24 ========\n",
      "098/099, 249s\t===== loss:0.19346, acc:0.93175\n",
      "\t\t=val= loss:0.92513, kappa:0.58735, acc:0.73136, IoU:0.59938\n",
      "Epoch: 129\t======== 开始时间 19-11-09 15:35:43 ========\n",
      "098/099, 249s\t===== loss:0.19331, acc:0.93170\n",
      "\t\t=val= loss:0.90919, kappa:0.59225, acc:0.73508, IoU:0.60451\n",
      "Epoch: 130\t======== 开始时间 19-11-09 15:47:02 ========\n",
      "098/099, 248s\t===== loss:0.19349, acc:0.93164\n",
      "\t\t=val= loss:0.91404, kappa:0.59058, acc:0.73361, IoU:0.60205\n",
      "Epoch: 131\t======== 开始时间 19-11-09 15:58:16 ========\n",
      "098/099, 247s\t===== loss:0.19305, acc:0.93176\n",
      "\t\t=val= loss:0.90934, kappa:0.59088, acc:0.73325, IoU:0.60219\n",
      "Epoch: 132\t======== 开始时间 19-11-09 16:09:22 ========\n",
      "098/099, 249s\t===== loss:0.19215, acc:0.93221\n",
      "\t\t=val= loss:0.91555, kappa:0.58983, acc:0.73316, IoU:0.60195\n",
      "降低学习率至0.0000000076,重新载入模型\n",
      "Epoch: 133\t======== 开始时间 19-11-09 16:20:40 ========\n",
      "098/099, 249s\t===== loss:0.19441, acc:0.93149\n",
      "\t\t=val= loss:0.91060, kappa:0.59124, acc:0.73428, IoU:0.60318\n",
      "Epoch: 134\t======== 开始时间 19-11-09 16:31:58 ========\n",
      "098/099, 249s\t===== loss:0.19394, acc:0.93127\n",
      "\t\t=val= loss:0.90950, kappa:0.59202, acc:0.73471, IoU:0.60400\n",
      "Epoch: 135\t======== 开始时间 19-11-09 16:43:17 ========\n",
      "098/099, 248s\t===== loss:0.19358, acc:0.93158\n",
      "\t\t=val= loss:0.92625, kappa:0.58541, acc:0.72897, IoU:0.59680\n",
      "Epoch: 136\t======== 开始时间 19-11-09 16:54:33 ========\n",
      "098/099, 249s\t===== loss:0.19372, acc:0.93147\n",
      "\t\t=val= loss:0.91381, kappa:0.59226, acc:0.73437, IoU:0.60412\n",
      "Epoch: 137\t======== 开始时间 19-11-09 17:05:51 ========\n",
      "098/099, 248s\t===== loss:0.19313, acc:0.93185\n",
      "\t\t=val= loss:0.91729, kappa:0.58962, acc:0.73288, IoU:0.60148\n",
      "降低学习率至0.0000000061,不重新载入模型\n",
      "Epoch: 138\t======== 开始时间 19-11-09 17:17:11 ========\n",
      "098/099, 249s\t===== loss:0.19476, acc:0.93125\n",
      "\t\t=val= loss:0.93095, kappa:0.58702, acc:0.73141, IoU:0.59941\n",
      "Epoch: 139\t======== 开始时间 19-11-09 17:28:27 ========\n",
      "098/099, 248s\t===== loss:0.19493, acc:0.93120\n",
      "\t\t=val= loss:0.91914, kappa:0.58992, acc:0.73264, IoU:0.60228\n",
      "Epoch: 140\t======== 开始时间 19-11-09 17:39:42 ========\n",
      "098/099, 249s\t===== loss:0.19784, acc:0.93076\n",
      "\t\t=val= loss:0.91674, kappa:0.58919, acc:0.73190, IoU:0.60074\n",
      "Epoch: 141\t======== 开始时间 19-11-09 17:50:59 ========\n",
      "098/099, 248s\t===== loss:0.19345, acc:0.93169\n",
      "\t\t=val= loss:0.92376, kappa:0.58932, acc:0.73197, IoU:0.60122\n",
      "Epoch: 142\t======== 开始时间 19-11-09 18:02:18 ========\n",
      "098/099, 250s\t===== loss:0.19649, acc:0.93129\n",
      "\t\t=val= loss:0.91721, kappa:0.59098, acc:0.73361, IoU:0.60349\n",
      "降低学习率至0.0000000049,不重新载入模型\n",
      "Epoch: 143\t======== 开始时间 19-11-09 18:13:38 ========\n",
      "098/099, 249s\t===== loss:0.19410, acc:0.93157\n",
      "\t\t=val= loss:0.91305, kappa:0.59113, acc:0.73397, IoU:0.60340\n",
      "Epoch: 144\t======== 开始时间 19-11-09 18:24:58 ========\n",
      "098/099, 249s\t===== loss:0.19477, acc:0.93118\n",
      "\t\t=val= loss:0.91268, kappa:0.59171, acc:0.73505, IoU:0.60396\n",
      "Epoch: 145\t======== 开始时间 19-11-09 18:36:17 ========\n",
      "098/099, 249s\t===== loss:0.19307, acc:0.93168\n",
      "\t\t=val= loss:0.91785, kappa:0.59004, acc:0.73262, IoU:0.60175\n",
      "Epoch: 146\t======== 开始时间 19-11-09 18:47:35 ========\n",
      "098/099, 249s\t===== loss:0.19458, acc:0.93131\n",
      "\t\t=val= loss:0.91161, kappa:0.59155, acc:0.73435, IoU:0.60336\n",
      "Epoch: 147\t======== 开始时间 19-11-09 18:58:52 ========\n",
      "098/099, 249s\t===== loss:0.19474, acc:0.93135\n",
      "\t\t=val= loss:0.91711, kappa:0.58990, acc:0.73341, IoU:0.60166\n",
      "降低学习率至0.0000000039,不重新载入模型\n",
      "Epoch: 148\t======== 开始时间 19-11-09 19:10:08 ========\n",
      "098/099, 249s\t===== loss:0.19508, acc:0.93109\n",
      "\t\t=val= loss:1.00798, kappa:0.55106, acc:0.69035, IoU:0.54765"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/a430/anaconda3/envs/torch-1.1/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/a430/anaconda3/envs/torch-1.1/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/a430/anaconda3/envs/torch-1.1/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/a430/anaconda3/envs/torch-1.1/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2dcd22b08d63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# check results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-dc76dfe41c14>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(val_loader, model, criterion, w, h)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mkappa_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcohen_kappa_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0macc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mjaccard_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjaccard_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;31m#f1_batch = f1_score(true, pred, average='weighted')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;31m#f1_batch_macro = f1_score(true, pred, average='macro')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch-1.1/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mjaccard_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    767\u001b[0m     MCM = multilabel_confusion_matrix(y_true, y_pred,\n\u001b[1;32m    768\u001b[0m                                       \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m                                       labels=labels, samplewise=samplewise)\n\u001b[0m\u001b[1;32m    770\u001b[0m     \u001b[0mnumerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMCM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMCM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch-1.1/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mmultilabel_confusion_matrix\u001b[0;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0msorted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch-1.1/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch-1.1/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch-1.1/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode_numpy\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode_check_unknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             raise ValueError(\"y contains previously unseen labels: %s\"\n",
      "\u001b[0;32m~/anaconda3/envs/torch-1.1/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode_check_unknown\u001b[0;34m(values, uniques, return_mask)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0munique_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massume_unique\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_mask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch-1.1/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch-1.1/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "# optimizer = optim.SGD(model.parameters(),lr = lr,momentum=0.9,weight_decay=1e-4)\n",
    "optimizer = optim.Adam(model.parameters(), lr, weight_decay=1e-4, amsgrad=True)\n",
    "#criterion = nn.NLLLoss2d().to(device)\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum', size_average=True).to(device)\n",
    "\n",
    "start_epoch = 0\n",
    "loss, kappa, acc, jaccard, f1, f1_macro = np.inf, 0, 0, 0, 0, 0\n",
    "best_results = [loss, kappa, acc, jaccard] #, f1, f1_macro]\n",
    "val_metrics = [loss, kappa, acc, jaccard] #, f1, f1_macro]\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print('使用多显卡训练')\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "#scheduler = lr_scheduler.StepLR(optimizer,step_size=20,gamma=0.5) #, verbose=True)\n",
    "#scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=8, cooldown = 3,verbose=True)\n",
    "#n_batches = int(len(train_loader.dataset) // train_loader.batch_size)\n",
    "#scheduler = CosineAnnealingLR(optimizer, T_max=n_batches*2)\n",
    "\n",
    "# 导入训练中断时的数据\n",
    "# weight_name = \"../weights/%s/kappa.pth.tar\"%(SaveName)\n",
    "# best_model = torch.load(weight_name)\n",
    "# a = list(best_model['state_dict'])\n",
    "# for i in range(len(a)):\n",
    "#     a[i] = a[i].replace('module.','',1)\n",
    "#     best_model['state_dict'][a[i]] = best_model['state_dict'].pop('module.'+a[i])\n",
    "# del a\n",
    "# model.load_state_dict(best_model['state_dict'])\n",
    "# start_epoch = best_model[\"epoch\"]\n",
    "# best_results = [best_model[\"best_loss\"], \n",
    "#                 best_model[\"best_kappa\"], \n",
    "#                 best_model[\"best_acc\"],\n",
    "#                 best_model[\"best_jaccard\"]]\n",
    "\n",
    "### 4.4 Training\n",
    "print(\"Start training...\\t%d epoches\"%(EPOCHES))\n",
    "circle = 0\n",
    "w,h = SIZE[0], SIZE[1]\n",
    "for epoch in range(start_epoch,EPOCHES):\n",
    "    now_time = time.strftime(\"%y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    message = 'Epoch: %d\\t======== 开始时间 %s ========\\n'%(epoch, now_time)\n",
    "    log.write(message,is_terminal=1)\n",
    "    # scheduler.step(epoch)\n",
    "    # train\n",
    "    train_metrics = train(train_loader,model,criterion,optimizer,w,h)\n",
    "    # val\n",
    "    print('\\n', end='',flush=True)\n",
    "    val_metrics = evaluate(valid_loader,model,criterion,w,h)\n",
    "    \n",
    "    # check results\n",
    "    is_best_loss = val_metrics[0] < best_results[0]\n",
    "    is_best_kappa = val_metrics[1] > best_results[1]\n",
    "    is_best_acc = val_metrics[2] > best_results[2]\n",
    "    is_best_jaccard = val_metrics[3] > best_results[3]\n",
    "    #is_best_f1, is_best_f1_macro = val_metrics[4] > best_results[4], val_metrics[5] > best_results[5]\n",
    "    best_results[0] = min(val_metrics[0],best_results[0])\n",
    "    for i in range(1,4):\n",
    "        best_results[i] = max(val_metrics[i],best_results[i])\n",
    "        \n",
    "    # save model\n",
    "    checkpoint = model.state_dict()\n",
    "    save_checkpoint({\"model_name\":SaveName, \"epoch\":epoch + 1,\n",
    "                     \"best_loss\":best_results[1], \"best_kappa\":best_results[0], \"best_acc\":best_results[2], \n",
    "                     \"best_jaccard\":best_results[3], \n",
    "                      # \"best_f1\":best_results[4],\"best_f1_macro\":best_results[5],\n",
    "                     \"state_dict\":checkpoint, \"optimizer\":optimizer.state_dict()}, \n",
    "                    SaveName, epoch+1, \n",
    "                    is_best_loss,is_best_kappa, is_best_acc, is_best_jaccard)#, is_best_f1, is_best_f1_macro)\n",
    "\n",
    "    print('\\n', end='',flush=True)\n",
    "\n",
    "    if is_best_loss:\n",
    "        circle = 0\n",
    "        print(\"==Get best LOSS in epoch %d: %0.8f \"%(epoch,best_results[0]))\n",
    "    else:\n",
    "        circle +=1\n",
    "    if is_best_kappa:\n",
    "        circle = 0\n",
    "        print(\"==Get best Kappa in epoch %d: %0.8f \"%(epoch,best_results[1])) \n",
    "    if is_best_acc:\n",
    "        circle = 0\n",
    "        print(\"==Get best ACC in epoch %d: %0.8f\"%(epoch,best_results[2]))\n",
    "    if is_best_jaccard:\n",
    "        circle = 0\n",
    "        print(\"==Get best IoU in epoch %d: %0.8f\"%(epoch,best_results[3]))\n",
    "#     if is_best_f1:\n",
    "#         circle = 0\n",
    "#         print(\"==Get best F1 in epoch %d: %0.8f\"%(epoch,best_results[4]))\n",
    "#     if is_best_f1_macro:\n",
    "#         circle = 0\n",
    "#         print(\"==Get best F1-macro in epoch %d: %0.8f\"%(epoch,best_results[5]))\n",
    "    # new Lr    \n",
    "    if circle >= 5:\n",
    "        if lr >= 1e-8:\n",
    "            lr *= 0.5\n",
    "            circle=0\n",
    "            optimizer = optim.Adam(model.parameters(), lr, weight_decay=1e-4, amsgrad=True)\n",
    "            print(\"降低学习率至%0.10f,重新载入模型\"%(lr))\n",
    "            model.load_state_dict(torch.load( \"../weights/%s/kappa.pth.tar\"%(SaveName))['state_dict'])\n",
    "        elif lr < 1e-12:\n",
    "            break\n",
    "        else:\n",
    "            lr *= 0.8\n",
    "            circle=0\n",
    "            optimizer = optim.Adam(model.parameters(), lr, weight_decay=1e-4, amsgrad=True)\n",
    "            print(\"降低学习率至%0.10f,不重新载入模型\"%(lr))\n",
    "            \n",
    "    time.sleep(0.1)\n",
    "    \n",
    "log.write(\"\\n LOSS:%0.8f\\tKappa:%0.8f\\tACC:%0.8f\\tIoU:%0.8f\"%(\n",
    "            best_results[0], best_results[1], best_results[2],best_results[3]),is_terminal=1)\n",
    "log.write(\"\\n\\n\",is_terminal=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 预测\n",
    "### 4.7.1 预测参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation.test import *\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "SaveName = '00-baseline-3CH-UNet-resnet18'\n",
    "metric = \"kappa\"\n",
    "multiGPU = 0\n",
    "NUM_TEST = 10     # 测试集大图的张数\n",
    "BS = 40        # 训练集batch-size，测试集将×4\n",
    "TestFileName = '../data/test_1106.npy'   # 测试集numpy位置\n",
    "SIZE = [576,576, 3]\n",
    "\n",
    "# 预测结果的输出文件夹\n",
    "SAVENAME = ['20150212_L1A0000647768_4.npy', '20150217_L1A0000658637_2.npy', '20150902_L1A0001015649_2.npy',\n",
    "            '20151203_L1A0001217916_1.npy', '20160225_L1A0001433318_3.npy', '20160327_L1A0001491417_3.npy',\n",
    "            '20160421_L1A0001537716_2.npy', '20160510_L1A0001573999_2.npy', '20160816_L1A0001765570_2.npy',\n",
    "            '20160827_L1A0001793003_2.npy']\n",
    "SAVEPATH = os.path.join(\"../results\", \"{}_{}\".format(SaveName, metric))\n",
    "if not os.path.exists(SAVEPATH):\n",
    "    os.makedirs(SAVEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7.2 载入预测模型\n",
    "\n",
    "* **请运行4.5 定义模型部分代码**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用模型为 00-baseline-3CH-UNet-resnet18/kappa : 0.85141 in 16 epoch\n"
     ]
    }
   ],
   "source": [
    "weight_name =  \"../weights/{}/{}.pth.tar\".format(SaveName, metric)\n",
    "if multiGPU:      #torch.cuda.device_count() > 1:     \n",
    "    print('训练的模型为多卡，需要使用多卡预测或修改代码！')\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "best_model = torch.load(weight_name)\n",
    "# 轮次不同，进行预测。轮次相同不预测\n",
    "model.load_state_dict(best_model[\"state_dict\"])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "if metric != \"checkpoint\":\n",
    "    best_metric = best_model['best_{}'.format(metric)]\n",
    "    best_epoch = best_model[\"epoch\"]\n",
    "    print(\"使用模型为 %s == %s : %0.5f in %d epoch\"%(weight_name, metric, best_metric, best_epoch))\n",
    "else:\n",
    "    print(\"使用模型为 %s/%s \"%(SaveName, metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7.3 读入预测文件与模型预测 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:12<00:00,  6.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../results/00-baseline-3CH-UNet-resnet18_kappa/20150212_L1A0000647768_4.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../results/00-baseline-3CH-UNet-resnet18_kappa/20150217_L1A0000658637_2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../results/00-baseline-3CH-UNet-resnet18_kappa/20150902_L1A0001015649_2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../results/00-baseline-3CH-UNet-resnet18_kappa/20151203_L1A0001217916_1.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../results/00-baseline-3CH-UNet-resnet18_kappa/20160225_L1A0001433318_3.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../results/00-baseline-3CH-UNet-resnet18_kappa/20160327_L1A0001491417_3.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../results/00-baseline-3CH-UNet-resnet18_kappa/20160421_L1A0001537716_2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../results/00-baseline-3CH-UNet-resnet18_kappa/20160510_L1A0001573999_2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../results/00-baseline-3CH-UNet-resnet18_kappa/20160816_L1A0001765570_2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:07<00:00,  3.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../results/00-baseline-3CH-UNet-resnet18_kappa/20160827_L1A0001793003_2.npy\n"
     ]
    }
   ],
   "source": [
    "test_file = np.load(TestFileName)[:,:,:,1:4]   # 3CH代码需要变为三通道\n",
    "num_test_each = test_file.shape[0]//NUM_TEST\n",
    "\n",
    "for i in range(NUM_TEST):\n",
    "    test_npy = test_file[num_test_each*i : num_test_each*(i+1)+1]\n",
    "    test_dataset = Dataset(test_npy, np.array([[0]*len(test_npy)]), \n",
    "                           size = SIZE, \n",
    "                           augmentation=None, \n",
    "                           #get_training_augmentation(), \n",
    "                           preprocessing=None, \n",
    "                           #get_preprocessing(preprocessing_fn)\n",
    "                           mode = 'test'\n",
    "                          )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BS*2, shuffle=False, num_workers=1)\n",
    "    # 模型预测\n",
    "    result = []\n",
    "    for image,_ in test_loader:\n",
    "        with torch.no_grad():\n",
    "            image_var = image.to(device)\n",
    "            # print(image_var.size())\n",
    "            y_pred = model(image_var)    # 预测\n",
    "            label = F.softmax(y_pred).cpu().data.numpy()\n",
    "            # label形如(BS,16,576,576), 其中16为类别数,即置信度\n",
    "            result.extend(label)\n",
    "            \n",
    "    result = np.array(result).transpose([0,2,3,1]) # 将list变为numpy并把置信度放在最后一个维度\n",
    "    one_hot_result = get_large(result, unit_size=576, step=288, width=3600, height=3400)\n",
    "    last = vis_label(one_hot_result)\n",
    "    #plt.rcParams['figure.dpi'] = 120\n",
    "    #plt.figure()\n",
    "    #plt.imshow(last), plt.axis('off')\n",
    "    print(\"Saving to {}/{}\".format(SAVEPATH,SAVENAME[i]))    \n",
    "    OutName = os.path.join(SAVEPATH, os.path.splitext(SAVENAME[i])[0]+'_test.tif')\n",
    "    last = last.astype(np.uint8)    \n",
    "    skimage.external.tifffile.imsave(OutName, last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 预测结果分析\n",
    "### 4.8.1 全类别结果读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [08:17<00:00, 49.34s/it]\n"
     ]
    }
   ],
   "source": [
    "ALL_y_pred, ALL_y_true = [],[]\n",
    "P, R, ACC = [],[],[]\n",
    "K, F1, F1_W, F1_micro, J, J_W, J_micro = [],[],[],[],[],[],[]\n",
    "class_report_f1 = [ [] for i in range(16)]\n",
    "\n",
    "for name in tqdm(SAVENAME):\n",
    "    #name = SAVENAME[0]\n",
    "    result_path = os.path.join(SAVEPATH, os.path.splitext(name)[0]+'_test.tif')\n",
    "    label_path = os.path.join('../data/test_1106', os.path.splitext(name)[0]+'_label_clsindex.npy')  \n",
    "\n",
    "    result = skimage.external.tifffile.imread(result_path)\n",
    "    label = np.load(label_path)\n",
    "    if result.shape[0] != label.shape[0] or result.shape[1] != label.shape[1]:\n",
    "        print(\"错误！结果与标签尺寸不相等，结果为{}，标签为{}\".format(result.shape, label.shape))\n",
    "\n",
    "    result = get_cls_index(result)\n",
    "    result = result.reshape(-1)\n",
    "    label = label.reshape(-1)\n",
    "    \n",
    "    # 全部图片\n",
    "    ALL_y_pred.append(result)\n",
    "    ALL_y_true.append(label)\n",
    "    \n",
    "    # 调用计算metric的函数\n",
    "    CAL = calculate(result, label, cm=False)\n",
    "    P.append(CAL['P'])\n",
    "    R.append(CAL['R'])\n",
    "    ACC.append(CAL['ACC'])\n",
    "    K.append(CAL['K'])\n",
    "    F1.append(CAL['F1'])\n",
    "    F1_W.append(CAL['F1-W'])\n",
    "    F1_micro.append(CAL['F1-micro'])\n",
    "    J.append(CAL['J'])\n",
    "    J_W.append(CAL['J-W'])\n",
    "    J_micro.append(CAL['J-micro'])\n",
    "    for i in range(16):\n",
    "        class_report_f1[i].append(CAL['CP']['{}'.format(i)]['f1-score'])\n",
    "\n",
    "# 所有文件合并为一个\n",
    "ALL_y_pred, ALL_y_true = np.array(ALL_y_pred).reshape(-1), np.array(ALL_y_true).reshape(-1)  \n",
    "# 调用计算metric的函数\n",
    "CAL = calculate(ALL_y_pred, ALL_y_true, cm=True)\n",
    "P.append(CAL['P'])\n",
    "R.append(CAL['R'])\n",
    "ACC.append(CAL['ACC'])\n",
    "K.append(CAL['K'])\n",
    "F1.append(CAL['F1'])\n",
    "F1_W.append(CAL['F1-W'])\n",
    "F1_micro.append(CAL['F1-micro'])\n",
    "J.append(CAL['J'])\n",
    "J_W.append(CAL['J-W'])\n",
    "J_micro.append(CAL['J-micro'])\n",
    "for i in range(16):\n",
    "    class_report_f1[i].append(CAL['CP']['{}'.format(i)]['f1-score'])\n",
    "CM = CAL['CM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8.2 五类别分析\n",
    "### 4.8.3 文件保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa:0.6449582815238115, F1:0.7511957587337367, Jaccard:0.6179116639201255\n"
     ]
    }
   ],
   "source": [
    "# 保存为相关文件\n",
    "filename_list = [SAVENAME[i].split('.')[0] for i in range(10)]\n",
    "filename_list.append('ALL')\n",
    "\n",
    "dic = {'filename':filename_list, \n",
    "       'precision-micro':P, 'recall-micro':R, 'accuracy':ACC, 'kappa':K, \n",
    "       'F1-macro':F1, 'F1-weighted':F1_W, 'F1-micro':F1_micro,\n",
    "       'jaccard-macro':J, 'jaccard-weighted':J_W, 'jaccard-micro':J_micro,\n",
    "       'unknown':class_report_f1[0],\n",
    "       'paddy field':class_report_f1[1],\n",
    "       'irrigated land':class_report_f1[2],\n",
    "       'dry land':class_report_f1[3],\n",
    "       'garden land':class_report_f1[4],\n",
    "       'arbor forest':class_report_f1[5],\n",
    "       'shrub land':class_report_f1[6],\n",
    "       'natural meadow':class_report_f1[7],\n",
    "       'artificial meadow':class_report_f1[8],\n",
    "       'industrial land':class_report_f1[9],\n",
    "       'urban residential':class_report_f1[10],\n",
    "       'rural residential':class_report_f1[11],\n",
    "       'traffic land':class_report_f1[12],\n",
    "       'river':class_report_f1[13],\n",
    "       'lake':class_report_f1[14],\n",
    "       'pond':class_report_f1[15]\n",
    "      }\n",
    "\n",
    "df = pd.DataFrame(dic)\n",
    "df.to_csv(os.path.join(SAVEPATH, '{}_metrics_result.csv'.format(SaveName)), index=None)\n",
    "np.save(os.path.join(SAVEPATH, 'confusion_matrix_{}.npy'.format(SaveName)),CM)\n",
    "print(\"Kappa:{}, F1:{}, Jaccard:{}\".format(CAL['K'], CAL['F1-W'], CAL['J-W']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8.4 混淆矩阵保存\n",
    "* **混淆矩阵的图像生成需要使用py文件**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-03b616ca887c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVEPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'confusion_matrix_{}.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSaveName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# plot_confusion_matrix(CM, np.arange(16))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# plt.savefig(os.path.join(SAVEPATH, '{}_metrics_result.png'.format(SaveName)), format='png')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "CM = np.load(os.path.join(SAVEPATH, 'confusion_matrix_{}.npy'.format(SaveName)))\n",
    "# plot_confusion_matrix(CM, np.arange(16))\n",
    "# plt.savefig(os.path.join(SAVEPATH, '{}_metrics_result.png'.format(SaveName)), format='png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
